{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNR finder ANN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from ler.utils import add_dict_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128675"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "from ler.utils import append_json, load_json\n",
    "import numpy as np\n",
    "\n",
    "# joint two dict\n",
    "unlensed_params = load_json(\"snr_L1.json\")\n",
    "unlensed_params2 = load_json(\"joint_new_optsnr.json\")\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params2)\n",
    "del unlensed_params2\n",
    "\n",
    "# randomize the data\n",
    "idx_shuffle = np.random.permutation(len(unlensed_params['L1']))\n",
    "for key, value in unlensed_params.items():\n",
    "    unlensed_params[key] = np.array(value)[idx_shuffle]\n",
    "\n",
    "len(unlensed_params['L1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "test = np.array(unlensed_params['L1'])\n",
    "test = test[test<20]\n",
    "plt.hist(test, bins=30)\n",
    "plt.xlim(0,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psds not given. Choosing bilby's default psds\n",
      "npool:  4\n",
      "snr type:  ann\n",
      "waveform approximant:  IMRPhenomXPHM\n",
      "sampling frequency:  2048.0\n",
      "minimum frequency (fmin):  20.0\n",
      "mtot=mass1+mass2\n",
      "min(mtot):  2.0\n",
      "max(mtot) (with the given fmin=20.0): 184.98599853446768\n",
      "detectors:  None\n",
      "ANN method is selected.\n",
      "Please be patient while the interpolator is generated of partialscaledSNR for IMRPhenomD.\n",
      "Interpolator will be loaded for L1 detector from ./interpolator_pickle/L1/partialSNR_dict_1.pickle\n",
      "Interpolator will be loaded for H1 detector from ./interpolator_pickle/H1/partialSNR_dict_1.pickle\n",
      "Interpolator will be loaded for V1 detector from ./interpolator_pickle/V1/partialSNR_dict_1.pickle\n"
     ]
    }
   ],
   "source": [
    "# let's generate IMRPhenomD (spinless) interpolartor\n",
    "from gwsnr import GWSNR\n",
    "gwsnr = GWSNR(snr_type='ann', waveform_approximant='IMRPhenomXPHM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input-Output generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwsnr import antenna_response_array, cubic_spline_interpolator2d\n",
    "\n",
    "def input_output(idx, params):\n",
    "\n",
    "    mass_1 = np.array(params['mass_1'])[idx]\n",
    "    mass_2 = np.array(params['mass_2'])[idx]\n",
    "    luminosity_distance = np.array(params['luminosity_distance'])[idx]\n",
    "    theta_jn = np.array(params['theta_jn'])[idx]\n",
    "    psi = np.array(params['psi'])[idx]\n",
    "    geocent_time = np.array(params['geocent_time'])[idx]\n",
    "    ra = np.array(params['ra'])[idx]\n",
    "    dec = np.array(params['dec'])[idx]\n",
    "    \n",
    "    detector_tensor = gwsnr.detector_tensor_list\n",
    "    snr_halfscaled = np.array(gwsnr.snr_partialsacaled_list)\n",
    "    ratio_arr = gwsnr.ratio_arr\n",
    "    mtot_arr = gwsnr.mtot_arr\n",
    "    \n",
    "    size = len(mass_1)\n",
    "    len_ = len(detector_tensor)\n",
    "    mtot = mass_1 + mass_2\n",
    "    ratio = mass_2 / mass_1\n",
    "    # get array of antenna response\n",
    "    Fp, Fc = antenna_response_array(ra, dec, geocent_time, psi, detector_tensor)\n",
    "\n",
    "    Mc = ((mass_1 * mass_2) ** (3 / 5)) / ((mass_1 + mass_2) ** (1 / 5))\n",
    "    eta = mass_1 * mass_2/(mass_1 + mass_2)**2.\n",
    "    A1 = Mc ** (5.0 / 6.0)\n",
    "    ci_2 = np.cos(theta_jn) ** 2\n",
    "    ci_param = ((1 + np.cos(theta_jn) ** 2) / 2) ** 2\n",
    "    \n",
    "    size = len(mass_1)\n",
    "    snr_half_ = np.zeros((len_,size))\n",
    "    d_eff = np.zeros((len_,size))\n",
    "\n",
    "    # loop over the detectors\n",
    "    for j in range(len_):\n",
    "        # loop over the parameter points\n",
    "        for i in range(size):\n",
    "            snr_half_coeff = snr_halfscaled[j]\n",
    "            snr_half_[j,i] = cubic_spline_interpolator2d(mtot[i], ratio[i], snr_half_coeff, mtot_arr, ratio_arr)\n",
    "            d_eff[j,i] =luminosity_distance[i] / np.sqrt(\n",
    "                    Fp[j,i]**2 * ci_param[i] + Fc[j,i]**2 * ci_2[i]\n",
    "                )\n",
    "\n",
    "    #amp0\n",
    "    amp0 =  A1 / d_eff\n",
    "\n",
    "    # get spin parameters\n",
    "    a_1 = np.array(params['a_1'])[idx]\n",
    "    a_2 = np.array(params['a_2'])[idx]\n",
    "    tilt_1 = np.array(params['tilt_1'])[idx]\n",
    "    tilt_2 = np.array(params['tilt_2'])[idx]\n",
    "    # phi_12 = np.array(params['phi_12'])[idx]\n",
    "    # phi_jl = np.array(params['phi_jl'])[idx]\n",
    "\n",
    "    # effective spin\n",
    "    chi_eff = (mass_1 * a_1 * np.cos(tilt_1) + mass_2 * a_2 * np.cos(tilt_2)) / (mass_1 + mass_2)\n",
    "\n",
    "\n",
    "    # input data\n",
    "    # error=2.41%, 3.60%\n",
    "    # XL1 = np.vstack([snr_half_[0], amp0[0], eta, a_1, a_2, tilt_1, tilt_2]).T\n",
    "    # XH1 = np.vstack([snr_half_[1], amp0[1], eta, a_1, a_2, tilt_1, tilt_2]).T\n",
    "    # XV1 = np.vstack([snr_half_[2], amp0[2], eta, a_1, a_2, tilt_1, tilt_2]).T\n",
    "\n",
    "    # error=2.72%, 3.32%\n",
    "    # XL1 = np.vstack([snr_half_[0], amp0[0], eta, a_1, a_2, tilt_1, tilt_2, phi_12, phi_jl]).T\n",
    "    # XH1 = np.vstack([snr_half_[1], amp0[1], eta, a_1, a_2, tilt_1, tilt_2, phi_12, phi_jl]).T\n",
    "    # XV1 = np.vstack([snr_half_[2], amp0[2], eta, a_1, a_2, tilt_1, tilt_2, phi_12, phi_jl]).T\n",
    "\n",
    "    # error=2.79%, 3.28%\n",
    "    XL1 = np.vstack([snr_half_[0], amp0[0], eta, chi_eff]).T\n",
    "    XH1 = np.vstack([snr_half_[1], amp0[1], eta, chi_eff]).T\n",
    "    XV1 = np.vstack([snr_half_[2], amp0[2], eta, chi_eff]).T    \n",
    "\n",
    "    # output data\n",
    "    # get L1 snr for y train\n",
    "    yL1 = params['L1'][idx]\n",
    "    yH1 = params['H1'][idx]\n",
    "    yV1 = params['V1'][idx]\n",
    "\n",
    "\n",
    "    return(XL1, XH1, XV1, yL1, yH1, yV1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128675, 4)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_ = len(unlensed_params['L1'])\n",
    "idx = np.arange(len_)\n",
    "# randomize the train set\n",
    "idx = np.random.permutation(idx)\n",
    "XL1, XH1, XV1, yL1, yH1, yV1 = input_output(idx, unlensed_params)\n",
    "np.shape(XL1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(XL1, yL1, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the scaler\n",
    "import pickle\n",
    "pickle.dump(sc, open('scalerL1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ANN\n",
    "ann = tf.keras.models.Sequential() \n",
    "\n",
    "# adding the input layer and the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=4, activation='relu'))\n",
    "# adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "# adding the third hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='sigmoid'))\n",
    "# adding the output layer, absolute value of the snr\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "#ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the ANN\n",
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.6568 - accuracy: 6.9944e-04\n",
      "Epoch 2/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.6071 - accuracy: 6.9080e-04\n",
      "Epoch 3/200\n",
      "3619/3619 [==============================] - 2s 429us/step - loss: 0.6154 - accuracy: 6.9080e-04\n",
      "Epoch 4/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.6589 - accuracy: 7.7716e-04\n",
      "Epoch 5/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.6535 - accuracy: 7.3398e-04\n",
      "Epoch 6/200\n",
      "3619/3619 [==============================] - 2s 511us/step - loss: 0.5897 - accuracy: 7.6852e-04\n",
      "Epoch 7/200\n",
      "3619/3619 [==============================] - 2s 454us/step - loss: 0.6180 - accuracy: 6.8217e-04\n",
      "Epoch 8/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.6223 - accuracy: 7.7716e-04\n",
      "Epoch 9/200\n",
      "3619/3619 [==============================] - 2s 429us/step - loss: 0.6266 - accuracy: 8.1170e-04\n",
      "Epoch 10/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.6024 - accuracy: 7.8579e-04\n",
      "Epoch 11/200\n",
      "3619/3619 [==============================] - 2s 433us/step - loss: 0.6071 - accuracy: 7.8579e-04\n",
      "Epoch 12/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.6131 - accuracy: 8.0306e-04\n",
      "Epoch 13/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.6742 - accuracy: 7.2534e-04\n",
      "Epoch 14/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.5798 - accuracy: 8.1170e-04\n",
      "Epoch 15/200\n",
      "3619/3619 [==============================] - 2s 429us/step - loss: 0.6093 - accuracy: 7.8579e-04\n",
      "Epoch 16/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.5965 - accuracy: 8.6351e-04\n",
      "Epoch 17/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5770 - accuracy: 8.3760e-04\n",
      "Epoch 18/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5713 - accuracy: 8.1170e-04\n",
      "Epoch 19/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.5918 - accuracy: 8.1170e-04\n",
      "Epoch 20/200\n",
      "3619/3619 [==============================] - 2s 434us/step - loss: 0.5621 - accuracy: 8.2033e-04\n",
      "Epoch 21/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.6526 - accuracy: 8.2033e-04\n",
      "Epoch 22/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.6376 - accuracy: 8.5487e-04\n",
      "Epoch 23/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.6347 - accuracy: 8.9805e-04\n",
      "Epoch 24/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5999 - accuracy: 9.2395e-04\n",
      "Epoch 25/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.5907 - accuracy: 9.4986e-04\n",
      "Epoch 26/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.6291 - accuracy: 8.9805e-04\n",
      "Epoch 27/200\n",
      "3619/3619 [==============================] - 2s 427us/step - loss: 0.5785 - accuracy: 9.6713e-04\n",
      "Epoch 28/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.6159 - accuracy: 8.9805e-04\n",
      "Epoch 29/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.5776 - accuracy: 9.6713e-04\n",
      "Epoch 30/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.6036 - accuracy: 9.6713e-04\n",
      "Epoch 31/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.5705 - accuracy: 9.5849e-04\n",
      "Epoch 32/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.5641 - accuracy: 9.6713e-04\n",
      "Epoch 33/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.6156 - accuracy: 9.3259e-04\n",
      "Epoch 34/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.5908 - accuracy: 0.0010\n",
      "Epoch 35/200\n",
      "3619/3619 [==============================] - 2s 434us/step - loss: 0.5815 - accuracy: 9.8440e-04\n",
      "Epoch 36/200\n",
      "3619/3619 [==============================] - 2s 431us/step - loss: 0.5477 - accuracy: 0.0010\n",
      "Epoch 37/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.5874 - accuracy: 9.8440e-04\n",
      "Epoch 38/200\n",
      "3619/3619 [==============================] - 2s 431us/step - loss: 0.6229 - accuracy: 0.0010\n",
      "Epoch 39/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5510 - accuracy: 0.0010\n",
      "Epoch 40/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.5759 - accuracy: 0.0010\n",
      "Epoch 41/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.6161 - accuracy: 0.0010\n",
      "Epoch 42/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.6087 - accuracy: 0.0011\n",
      "Epoch 43/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5879 - accuracy: 0.0010\n",
      "Epoch 44/200\n",
      "3619/3619 [==============================] - 2s 428us/step - loss: 0.5778 - accuracy: 0.0011\n",
      "Epoch 45/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.5610 - accuracy: 0.0011\n",
      "Epoch 46/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.5976 - accuracy: 0.0011\n",
      "Epoch 47/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.5766 - accuracy: 0.0011\n",
      "Epoch 48/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5853 - accuracy: 0.0011\n",
      "Epoch 49/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.6259 - accuracy: 0.0011\n",
      "Epoch 50/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.5484 - accuracy: 0.0011\n",
      "Epoch 51/200\n",
      "3619/3619 [==============================] - 2s 427us/step - loss: 0.6348 - accuracy: 0.0011\n",
      "Epoch 52/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.5499 - accuracy: 0.0011\n",
      "Epoch 53/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.5988 - accuracy: 0.0011\n",
      "Epoch 54/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5384 - accuracy: 0.0011\n",
      "Epoch 55/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.5456 - accuracy: 0.0012\n",
      "Epoch 56/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.6108 - accuracy: 0.0011\n",
      "Epoch 57/200\n",
      "3619/3619 [==============================] - 2s 431us/step - loss: 0.5762 - accuracy: 0.0012\n",
      "Epoch 58/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.5278 - accuracy: 0.0011\n",
      "Epoch 59/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.5403 - accuracy: 0.0011\n",
      "Epoch 60/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.5906 - accuracy: 0.0011\n",
      "Epoch 61/200\n",
      "3619/3619 [==============================] - 2s 444us/step - loss: 0.5732 - accuracy: 0.0011\n",
      "Epoch 62/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.5918 - accuracy: 0.0012\n",
      "Epoch 63/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5517 - accuracy: 0.0012\n",
      "Epoch 64/200\n",
      "3619/3619 [==============================] - 2s 431us/step - loss: 0.5322 - accuracy: 0.0011\n",
      "Epoch 65/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.5274 - accuracy: 0.0011\n",
      "Epoch 66/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.5662 - accuracy: 0.0012\n",
      "Epoch 67/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.5609 - accuracy: 0.0012\n",
      "Epoch 68/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.5348 - accuracy: 0.0011\n",
      "Epoch 69/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.5960 - accuracy: 0.0012\n",
      "Epoch 70/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.5019 - accuracy: 0.0012\n",
      "Epoch 71/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.5921 - accuracy: 0.0012\n",
      "Epoch 72/200\n",
      "3619/3619 [==============================] - 2s 444us/step - loss: 0.5387 - accuracy: 0.0012\n",
      "Epoch 73/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.5564 - accuracy: 0.0011\n",
      "Epoch 74/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.5774 - accuracy: 0.0012\n",
      "Epoch 75/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.5840 - accuracy: 0.0012\n",
      "Epoch 76/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.5481 - accuracy: 0.0012\n",
      "Epoch 77/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.5149 - accuracy: 0.0012\n",
      "Epoch 78/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.5471 - accuracy: 0.0012\n",
      "Epoch 79/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.6077 - accuracy: 0.0012\n",
      "Epoch 80/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5799 - accuracy: 0.0012\n",
      "Epoch 81/200\n",
      "3619/3619 [==============================] - 2s 433us/step - loss: 0.5408 - accuracy: 0.0012\n",
      "Epoch 82/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.5686 - accuracy: 0.0012\n",
      "Epoch 83/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.5232 - accuracy: 0.0012\n",
      "Epoch 84/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.5333 - accuracy: 0.0012\n",
      "Epoch 85/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.4999 - accuracy: 0.0012\n",
      "Epoch 86/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5925 - accuracy: 0.0012\n",
      "Epoch 87/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.5809 - accuracy: 0.0012\n",
      "Epoch 88/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5492 - accuracy: 0.0012\n",
      "Epoch 89/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5820 - accuracy: 0.0012\n",
      "Epoch 90/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5098 - accuracy: 0.0012\n",
      "Epoch 91/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.5810 - accuracy: 0.0012\n",
      "Epoch 92/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.5169 - accuracy: 0.0012\n",
      "Epoch 93/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.5418 - accuracy: 0.0012\n",
      "Epoch 94/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5085 - accuracy: 0.0012\n",
      "Epoch 95/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.5345 - accuracy: 0.0012\n",
      "Epoch 96/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.4943 - accuracy: 0.0012\n",
      "Epoch 97/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5555 - accuracy: 0.0012\n",
      "Epoch 98/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.5517 - accuracy: 0.0013\n",
      "Epoch 99/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.5083 - accuracy: 0.0013\n",
      "Epoch 100/200\n",
      "3619/3619 [==============================] - 2s 456us/step - loss: 0.5713 - accuracy: 0.0012\n",
      "Epoch 101/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.4980 - accuracy: 0.0012\n",
      "Epoch 102/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.6026 - accuracy: 0.0013\n",
      "Epoch 103/200\n",
      "3619/3619 [==============================] - 2s 444us/step - loss: 0.6013 - accuracy: 0.0013\n",
      "Epoch 104/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.5131 - accuracy: 0.0013\n",
      "Epoch 105/200\n",
      "3619/3619 [==============================] - 2s 455us/step - loss: 0.5032 - accuracy: 0.0013\n",
      "Epoch 106/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.4976 - accuracy: 0.0013\n",
      "Epoch 107/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5880 - accuracy: 0.0013\n",
      "Epoch 108/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.4978 - accuracy: 0.0013\n",
      "Epoch 109/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.6209 - accuracy: 0.0013\n",
      "Epoch 110/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.5740 - accuracy: 0.0014\n",
      "Epoch 111/200\n",
      "3619/3619 [==============================] - 2s 454us/step - loss: 0.5993 - accuracy: 0.0013\n",
      "Epoch 112/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.4896 - accuracy: 0.0013\n",
      "Epoch 113/200\n",
      "3619/3619 [==============================] - 2s 456us/step - loss: 0.5363 - accuracy: 0.0014\n",
      "Epoch 114/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.4983 - accuracy: 0.0014\n",
      "Epoch 115/200\n",
      "3619/3619 [==============================] - 2s 457us/step - loss: 0.5440 - accuracy: 0.0013\n",
      "Epoch 116/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.5110 - accuracy: 0.0014\n",
      "Epoch 117/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.5547 - accuracy: 0.0014\n",
      "Epoch 118/200\n",
      "3619/3619 [==============================] - 2s 457us/step - loss: 0.5244 - accuracy: 0.0014\n",
      "Epoch 119/200\n",
      "3619/3619 [==============================] - 2s 456us/step - loss: 0.4761 - accuracy: 0.0015\n",
      "Epoch 120/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.6053 - accuracy: 0.0015\n",
      "Epoch 121/200\n",
      "3619/3619 [==============================] - 2s 462us/step - loss: 0.5384 - accuracy: 0.0014\n",
      "Epoch 122/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.5862 - accuracy: 0.0015\n",
      "Epoch 123/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.4743 - accuracy: 0.0015\n",
      "Epoch 124/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.5707 - accuracy: 0.0014\n",
      "Epoch 125/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.4875 - accuracy: 0.0015\n",
      "Epoch 126/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.5668 - accuracy: 0.0014\n",
      "Epoch 127/200\n",
      "3619/3619 [==============================] - 2s 461us/step - loss: 0.5562 - accuracy: 0.0015\n",
      "Epoch 128/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.6330 - accuracy: 0.0015\n",
      "Epoch 129/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.5600 - accuracy: 0.0014\n",
      "Epoch 130/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.4778 - accuracy: 0.0015\n",
      "Epoch 131/200\n",
      "3619/3619 [==============================] - 2s 463us/step - loss: 0.5792 - accuracy: 0.0015\n",
      "Epoch 132/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.5278 - accuracy: 0.0016\n",
      "Epoch 133/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.6020 - accuracy: 0.0016\n",
      "Epoch 134/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.5330 - accuracy: 0.0016\n",
      "Epoch 135/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.5647 - accuracy: 0.0016\n",
      "Epoch 136/200\n",
      "3619/3619 [==============================] - 2s 465us/step - loss: 0.5111 - accuracy: 0.0016\n",
      "Epoch 137/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.5346 - accuracy: 0.0016\n",
      "Epoch 138/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.5203 - accuracy: 0.0016\n",
      "Epoch 139/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.5352 - accuracy: 0.0016\n",
      "Epoch 140/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.5685 - accuracy: 0.0016\n",
      "Epoch 141/200\n",
      "3619/3619 [==============================] - 2s 457us/step - loss: 0.5283 - accuracy: 0.0016\n",
      "Epoch 142/200\n",
      "3619/3619 [==============================] - 2s 457us/step - loss: 0.5062 - accuracy: 0.0016\n",
      "Epoch 143/200\n",
      "3619/3619 [==============================] - 2s 461us/step - loss: 0.4837 - accuracy: 0.0016\n",
      "Epoch 144/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.5523 - accuracy: 0.0017\n",
      "Epoch 145/200\n",
      "3619/3619 [==============================] - 2s 456us/step - loss: 0.5650 - accuracy: 0.0017\n",
      "Epoch 146/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.5163 - accuracy: 0.0016\n",
      "Epoch 147/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.4762 - accuracy: 0.0017\n",
      "Epoch 148/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.4988 - accuracy: 0.0017\n",
      "Epoch 149/200\n",
      "3619/3619 [==============================] - 2s 461us/step - loss: 0.5407 - accuracy: 0.0017\n",
      "Epoch 150/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.5353 - accuracy: 0.0017\n",
      "Epoch 151/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.5443 - accuracy: 0.0017\n",
      "Epoch 152/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.5402 - accuracy: 0.0017\n",
      "Epoch 153/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.5132 - accuracy: 0.0017\n",
      "Epoch 154/200\n",
      "3619/3619 [==============================] - 2s 461us/step - loss: 0.4861 - accuracy: 0.0017\n",
      "Epoch 155/200\n",
      "3619/3619 [==============================] - 2s 464us/step - loss: 0.5480 - accuracy: 0.0017\n",
      "Epoch 156/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.5295 - accuracy: 0.0017\n",
      "Epoch 157/200\n",
      "3619/3619 [==============================] - 2s 455us/step - loss: 0.5162 - accuracy: 0.0017\n",
      "Epoch 158/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.5160 - accuracy: 0.0018\n",
      "Epoch 159/200\n",
      "3619/3619 [==============================] - 2s 462us/step - loss: 0.4957 - accuracy: 0.0017\n",
      "Epoch 160/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.5066 - accuracy: 0.0018\n",
      "Epoch 161/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.4689 - accuracy: 0.0018\n",
      "Epoch 162/200\n",
      "3619/3619 [==============================] - 2s 462us/step - loss: 0.4865 - accuracy: 0.0018\n",
      "Epoch 163/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.5280 - accuracy: 0.0019\n",
      "Epoch 164/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.5392 - accuracy: 0.0018\n",
      "Epoch 165/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.5160 - accuracy: 0.0019\n",
      "Epoch 166/200\n",
      "3619/3619 [==============================] - 2s 462us/step - loss: 0.5091 - accuracy: 0.0019\n",
      "Epoch 167/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.4752 - accuracy: 0.0019\n",
      "Epoch 168/200\n",
      "3619/3619 [==============================] - 2s 465us/step - loss: 0.5526 - accuracy: 0.0019\n",
      "Epoch 169/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.5618 - accuracy: 0.0019\n",
      "Epoch 170/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.5283 - accuracy: 0.0020\n",
      "Epoch 171/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.4780 - accuracy: 0.0020\n",
      "Epoch 172/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.6154 - accuracy: 0.0020\n",
      "Epoch 173/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.5106 - accuracy: 0.0020\n",
      "Epoch 174/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.5126 - accuracy: 0.0020\n",
      "Epoch 175/200\n",
      "3619/3619 [==============================] - 2s 462us/step - loss: 0.4745 - accuracy: 0.0020\n",
      "Epoch 176/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.4828 - accuracy: 0.0020\n",
      "Epoch 177/200\n",
      "3619/3619 [==============================] - 2s 461us/step - loss: 0.5306 - accuracy: 0.0020\n",
      "Epoch 178/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.4734 - accuracy: 0.0020\n",
      "Epoch 179/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.4747 - accuracy: 0.0020\n",
      "Epoch 180/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.5099 - accuracy: 0.0021\n",
      "Epoch 181/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.5177 - accuracy: 0.0020\n",
      "Epoch 182/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.5718 - accuracy: 0.0020\n",
      "Epoch 183/200\n",
      "3619/3619 [==============================] - 2s 461us/step - loss: 0.5601 - accuracy: 0.0021\n",
      "Epoch 184/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.4875 - accuracy: 0.0022\n",
      "Epoch 185/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.4763 - accuracy: 0.0022\n",
      "Epoch 186/200\n",
      "3619/3619 [==============================] - 2s 461us/step - loss: 0.4941 - accuracy: 0.0021\n",
      "Epoch 187/200\n",
      "3619/3619 [==============================] - 2s 462us/step - loss: 0.5008 - accuracy: 0.0022\n",
      "Epoch 188/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.5461 - accuracy: 0.0022\n",
      "Epoch 189/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.4761 - accuracy: 0.0022\n",
      "Epoch 190/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.4912 - accuracy: 0.0022\n",
      "Epoch 191/200\n",
      "3619/3619 [==============================] - 2s 457us/step - loss: 0.5386 - accuracy: 0.0022\n",
      "Epoch 192/200\n",
      "3619/3619 [==============================] - 2s 461us/step - loss: 0.4696 - accuracy: 0.0022\n",
      "Epoch 193/200\n",
      "3619/3619 [==============================] - 2s 457us/step - loss: 0.5259 - accuracy: 0.0022\n",
      "Epoch 194/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.5326 - accuracy: 0.0023\n",
      "Epoch 195/200\n",
      "3619/3619 [==============================] - 2s 457us/step - loss: 0.4855 - accuracy: 0.0023\n",
      "Epoch 196/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.5329 - accuracy: 0.0023\n",
      "Epoch 197/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.5237 - accuracy: 0.0023\n",
      "Epoch 198/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.4855 - accuracy: 0.0022\n",
      "Epoch 199/200\n",
      "3619/3619 [==============================] - 2s 463us/step - loss: 0.5325 - accuracy: 0.0023\n",
      "Epoch 200/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.5129 - accuracy: 0.0023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c4691480>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the ANN on the training set\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 200, workers=4, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403/403 [==============================] - 0s 391us/step\n",
      "[[ 2.70200205  2.82277302]\n",
      " [ 0.38870335  0.31006868]\n",
      " [ 5.60412502  5.24579823]\n",
      " [ 0.23539734  0.15386778]\n",
      " [ 3.12788582  3.23441804]\n",
      " [ 4.76398802  4.6486933 ]\n",
      " [ 4.31961775  4.13931754]\n",
      " [ 4.16287708  4.17185805]\n",
      " [ 4.89632607  4.97591135]\n",
      " [ 6.34074068  6.24072374]\n",
      " [12.06006718 12.54865096]\n",
      " [ 5.41409206  5.88138031]\n",
      " [21.37667465 20.17674523]\n",
      " [ 4.85266161  5.19735151]\n",
      " [12.32242012 12.78739858]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "#y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)[10:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 3.31%\n"
     ]
    }
   ],
   "source": [
    "len1 = len(y_pred)\n",
    "len2 = np.sum((y_pred.flatten()>6) != (y_test>6))\n",
    "error = len2/len1*100\n",
    "print(f\"Error: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12868\n",
      "5655\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = y_pred.flatten()\n",
    "# y_test = Y_\n",
    "hist_ = y_pred-y_test\n",
    "print(len(hist_))\n",
    "idx = (y_test>4) & (y_test<10)\n",
    "hist_ = hist_[idx]\n",
    "#hist_ = hist_[abs(hist_)<5.]\n",
    "print(len(hist_))\n",
    "plt.figure(figsize=(4,4)) \n",
    "plt.hist(hist_, bins=100, histtype='step', density=True)\n",
    "plt.xlim(-5,5)\n",
    "plt.xlabel('snr_ml and snr_inner_product difference')\n",
    "plt.ylabel('pdf')\n",
    "plt.grid(alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "ann.save('ann_modelL1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(XH1, yH1, test_size = 0.1, random_state = 0)\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# save the scaler\n",
    "import pickle\n",
    "pickle.dump(sc, open('scalerH1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ANN\n",
    "ann = tf.keras.models.Sequential() \n",
    "\n",
    "# adding the input layer and the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=4, activation='relu'))\n",
    "# adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "# adding the third hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='sigmoid'))\n",
    "# adding the output layer, absolute value of the snr\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "#ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the ANN\n",
    "# loss = 'mean_squared_error'\n",
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3619/3619 [==============================] - 2s 427us/step - loss: 10.2965 - accuracy: 1.1226e-04\n",
      "Epoch 2/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 3.4433 - accuracy: 2.6769e-04\n",
      "Epoch 3/200\n",
      "3619/3619 [==============================] - 2s 420us/step - loss: 2.3991 - accuracy: 3.5404e-04\n",
      "Epoch 4/200\n",
      "3619/3619 [==============================] - 2s 419us/step - loss: 1.9076 - accuracy: 2.9359e-04\n",
      "Epoch 5/200\n",
      "3619/3619 [==============================] - 2s 427us/step - loss: 1.6383 - accuracy: 3.4540e-04\n",
      "Epoch 6/200\n",
      "3619/3619 [==============================] - 2s 421us/step - loss: 1.4592 - accuracy: 3.0223e-04\n",
      "Epoch 7/200\n",
      "3619/3619 [==============================] - 2s 420us/step - loss: 1.3205 - accuracy: 3.0223e-04\n",
      "Epoch 8/200\n",
      "3619/3619 [==============================] - 1s 410us/step - loss: 1.2155 - accuracy: 3.3677e-04\n",
      "Epoch 9/200\n",
      "3619/3619 [==============================] - 2s 417us/step - loss: 1.1149 - accuracy: 3.1950e-04\n",
      "Epoch 10/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 1.0430 - accuracy: 3.4540e-04\n",
      "Epoch 11/200\n",
      "3619/3619 [==============================] - 2s 416us/step - loss: 0.9887 - accuracy: 3.1086e-04\n",
      "Epoch 12/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.9428 - accuracy: 3.2813e-04\n",
      "Epoch 13/200\n",
      "3619/3619 [==============================] - 2s 419us/step - loss: 0.9020 - accuracy: 3.0223e-04\n",
      "Epoch 14/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.8639 - accuracy: 3.6267e-04\n",
      "Epoch 15/200\n",
      "3619/3619 [==============================] - 2s 422us/step - loss: 0.8296 - accuracy: 3.1086e-04\n",
      "Epoch 16/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.8153 - accuracy: 3.1086e-04\n",
      "Epoch 17/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.7875 - accuracy: 3.3677e-04\n",
      "Epoch 18/200\n",
      "3619/3619 [==============================] - 2s 421us/step - loss: 0.7638 - accuracy: 3.3677e-04\n",
      "Epoch 19/200\n",
      "3619/3619 [==============================] - 2s 434us/step - loss: 0.7363 - accuracy: 3.7994e-04\n",
      "Epoch 20/200\n",
      "3619/3619 [==============================] - 2s 434us/step - loss: 0.7462 - accuracy: 3.4540e-04\n",
      "Epoch 21/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.7019 - accuracy: 3.5404e-04\n",
      "Epoch 22/200\n",
      "3619/3619 [==============================] - 2s 420us/step - loss: 0.7044 - accuracy: 3.0223e-04\n",
      "Epoch 23/200\n",
      "3619/3619 [==============================] - 2s 461us/step - loss: 0.6894 - accuracy: 3.8858e-04\n",
      "Epoch 24/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.6690 - accuracy: 3.8858e-04\n",
      "Epoch 25/200\n",
      "3619/3619 [==============================] - 2s 487us/step - loss: 0.6629 - accuracy: 3.9721e-04\n",
      "Epoch 26/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.6486 - accuracy: 3.7994e-04\n",
      "Epoch 27/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.6438 - accuracy: 3.6267e-04\n",
      "Epoch 28/200\n",
      "3619/3619 [==============================] - 2s 421us/step - loss: 0.6318 - accuracy: 3.9721e-04\n",
      "Epoch 29/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.6423 - accuracy: 3.1950e-04\n",
      "Epoch 30/200\n",
      "3619/3619 [==============================] - 2s 467us/step - loss: 0.6157 - accuracy: 3.7131e-04\n",
      "Epoch 31/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.6217 - accuracy: 3.9721e-04\n",
      "Epoch 32/200\n",
      "3619/3619 [==============================] - 2s 424us/step - loss: 0.6062 - accuracy: 3.6267e-04\n",
      "Epoch 33/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.6148 - accuracy: 4.1448e-04\n",
      "Epoch 34/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5960 - accuracy: 3.7131e-04\n",
      "Epoch 35/200\n",
      "3619/3619 [==============================] - 2s 429us/step - loss: 0.6228 - accuracy: 3.7131e-04\n",
      "Epoch 36/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.5853 - accuracy: 3.5404e-04\n",
      "Epoch 37/200\n",
      "3619/3619 [==============================] - 2s 415us/step - loss: 0.5973 - accuracy: 3.6267e-04\n",
      "Epoch 38/200\n",
      "3619/3619 [==============================] - 2s 433us/step - loss: 0.5747 - accuracy: 3.9721e-04\n",
      "Epoch 39/200\n",
      "3619/3619 [==============================] - 2s 428us/step - loss: 0.5887 - accuracy: 3.5404e-04\n",
      "Epoch 40/200\n",
      "3619/3619 [==============================] - 2s 428us/step - loss: 0.5846 - accuracy: 3.9721e-04\n",
      "Epoch 41/200\n",
      "3619/3619 [==============================] - 2s 416us/step - loss: 0.6023 - accuracy: 3.5404e-04\n",
      "Epoch 42/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5710 - accuracy: 4.1448e-04\n",
      "Epoch 43/200\n",
      "3619/3619 [==============================] - 2s 422us/step - loss: 0.5960 - accuracy: 3.8858e-04\n",
      "Epoch 44/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5685 - accuracy: 3.7131e-04\n",
      "Epoch 45/200\n",
      "3619/3619 [==============================] - 2s 416us/step - loss: 0.5868 - accuracy: 4.0585e-04\n",
      "Epoch 46/200\n",
      "3619/3619 [==============================] - 2s 417us/step - loss: 0.5626 - accuracy: 4.2312e-04\n",
      "Epoch 47/200\n",
      "3619/3619 [==============================] - 2s 427us/step - loss: 0.5695 - accuracy: 3.7994e-04\n",
      "Epoch 48/200\n",
      "3619/3619 [==============================] - 2s 423us/step - loss: 0.5791 - accuracy: 3.7131e-04\n",
      "Epoch 49/200\n",
      "3619/3619 [==============================] - 2s 428us/step - loss: 0.5638 - accuracy: 4.3175e-04\n",
      "Epoch 50/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.5772 - accuracy: 3.7131e-04\n",
      "Epoch 51/200\n",
      "3619/3619 [==============================] - 2s 424us/step - loss: 0.5557 - accuracy: 3.9721e-04\n",
      "Epoch 52/200\n",
      "3619/3619 [==============================] - 2s 422us/step - loss: 0.5654 - accuracy: 4.0585e-04\n",
      "Epoch 53/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.5764 - accuracy: 3.7131e-04\n",
      "Epoch 54/200\n",
      "3619/3619 [==============================] - 2s 420us/step - loss: 0.5441 - accuracy: 3.8858e-04\n",
      "Epoch 55/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.5527 - accuracy: 3.8858e-04\n",
      "Epoch 56/200\n",
      "3619/3619 [==============================] - 2s 428us/step - loss: 0.5649 - accuracy: 4.2312e-04\n",
      "Epoch 57/200\n",
      "3619/3619 [==============================] - 2s 425us/step - loss: 0.5737 - accuracy: 3.6267e-04\n",
      "Epoch 58/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.5488 - accuracy: 3.7131e-04\n",
      "Epoch 59/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.5600 - accuracy: 4.0585e-04\n",
      "Epoch 60/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5899 - accuracy: 3.7994e-04\n",
      "Epoch 61/200\n",
      "3619/3619 [==============================] - 2s 494us/step - loss: 0.5448 - accuracy: 4.3175e-04\n",
      "Epoch 62/200\n",
      "3619/3619 [==============================] - 2s 471us/step - loss: 0.5561 - accuracy: 4.0585e-04\n",
      "Epoch 63/200\n",
      "3619/3619 [==============================] - 2s 499us/step - loss: 0.5342 - accuracy: 4.0585e-04\n",
      "Epoch 64/200\n",
      "3619/3619 [==============================] - 2s 423us/step - loss: 0.5764 - accuracy: 3.9721e-04\n",
      "Epoch 65/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.5418 - accuracy: 3.5404e-04\n",
      "Epoch 66/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.5522 - accuracy: 4.0585e-04\n",
      "Epoch 67/200\n",
      "3619/3619 [==============================] - 2s 463us/step - loss: 0.5301 - accuracy: 4.1448e-04\n",
      "Epoch 68/200\n",
      "3619/3619 [==============================] - 2s 480us/step - loss: 0.5627 - accuracy: 4.2312e-04\n",
      "Epoch 69/200\n",
      "3619/3619 [==============================] - 2s 465us/step - loss: 0.5725 - accuracy: 4.6629e-04\n",
      "Epoch 70/200\n",
      "3619/3619 [==============================] - 2s 465us/step - loss: 0.5395 - accuracy: 4.1448e-04\n",
      "Epoch 71/200\n",
      "3619/3619 [==============================] - 2s 478us/step - loss: 0.6555 - accuracy: 4.3175e-04\n",
      "Epoch 72/200\n",
      "3619/3619 [==============================] - 2s 456us/step - loss: 0.5422 - accuracy: 4.3175e-04\n",
      "Epoch 73/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.5687 - accuracy: 4.2312e-04\n",
      "Epoch 74/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.5598 - accuracy: 4.4902e-04\n",
      "Epoch 75/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.5591 - accuracy: 4.2312e-04\n",
      "Epoch 76/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.5411 - accuracy: 4.5766e-04\n",
      "Epoch 77/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.5475 - accuracy: 3.8858e-04\n",
      "Epoch 78/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.5503 - accuracy: 4.0585e-04\n",
      "Epoch 79/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5439 - accuracy: 4.0585e-04\n",
      "Epoch 80/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5513 - accuracy: 4.3175e-04\n",
      "Epoch 81/200\n",
      "3619/3619 [==============================] - 2s 429us/step - loss: 0.5693 - accuracy: 3.9721e-04\n",
      "Epoch 82/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5314 - accuracy: 4.1448e-04\n",
      "Epoch 83/200\n",
      "3619/3619 [==============================] - 2s 433us/step - loss: 0.5293 - accuracy: 4.3175e-04\n",
      "Epoch 84/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5444 - accuracy: 4.2312e-04\n",
      "Epoch 85/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5326 - accuracy: 4.1448e-04\n",
      "Epoch 86/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5569 - accuracy: 3.9721e-04\n",
      "Epoch 87/200\n",
      "3619/3619 [==============================] - 2s 425us/step - loss: 0.5466 - accuracy: 3.3677e-04\n",
      "Epoch 88/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5523 - accuracy: 4.4039e-04\n",
      "Epoch 89/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.5489 - accuracy: 3.7994e-04\n",
      "Epoch 90/200\n",
      "3619/3619 [==============================] - 2s 469us/step - loss: 0.5346 - accuracy: 3.9721e-04\n",
      "Epoch 91/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.5128 - accuracy: 4.0585e-04\n",
      "Epoch 92/200\n",
      "3619/3619 [==============================] - 2s 484us/step - loss: 0.5745 - accuracy: 3.2813e-04\n",
      "Epoch 93/200\n",
      "3619/3619 [==============================] - 2s 457us/step - loss: 0.5443 - accuracy: 4.1448e-04\n",
      "Epoch 94/200\n",
      "3619/3619 [==============================] - 2s 464us/step - loss: 0.5538 - accuracy: 3.8858e-04\n",
      "Epoch 95/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.5364 - accuracy: 3.9721e-04\n",
      "Epoch 96/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.5342 - accuracy: 3.7131e-04\n",
      "Epoch 97/200\n",
      "3619/3619 [==============================] - 2s 472us/step - loss: 0.5371 - accuracy: 3.7131e-04\n",
      "Epoch 98/200\n",
      "3619/3619 [==============================] - 2s 464us/step - loss: 0.5588 - accuracy: 3.9721e-04\n",
      "Epoch 99/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5130 - accuracy: 4.0585e-04\n",
      "Epoch 100/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.5311 - accuracy: 4.2312e-04\n",
      "Epoch 101/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5500 - accuracy: 3.9721e-04\n",
      "Epoch 102/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.5066 - accuracy: 4.0585e-04\n",
      "Epoch 103/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.5929 - accuracy: 4.0585e-04\n",
      "Epoch 104/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5436 - accuracy: 4.1448e-04\n",
      "Epoch 105/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.5321 - accuracy: 3.8858e-04\n",
      "Epoch 106/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.5482 - accuracy: 3.8858e-04\n",
      "Epoch 107/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.5223 - accuracy: 4.1448e-04\n",
      "Epoch 108/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5675 - accuracy: 3.6267e-04\n",
      "Epoch 109/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5353 - accuracy: 3.8858e-04\n",
      "Epoch 110/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5269 - accuracy: 4.2312e-04\n",
      "Epoch 111/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.5350 - accuracy: 3.7131e-04\n",
      "Epoch 112/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5412 - accuracy: 3.7994e-04\n",
      "Epoch 113/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.5270 - accuracy: 4.4039e-04\n",
      "Epoch 114/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5133 - accuracy: 4.1448e-04\n",
      "Epoch 115/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5264 - accuracy: 3.8858e-04\n",
      "Epoch 116/200\n",
      "3619/3619 [==============================] - 2s 484us/step - loss: 0.5439 - accuracy: 4.3175e-04\n",
      "Epoch 117/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.5712 - accuracy: 4.2312e-04\n",
      "Epoch 118/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.5393 - accuracy: 3.8858e-04\n",
      "Epoch 119/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.5359 - accuracy: 3.6267e-04\n",
      "Epoch 120/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.5551 - accuracy: 3.9721e-04\n",
      "Epoch 121/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.5357 - accuracy: 4.2312e-04\n",
      "Epoch 122/200\n",
      "3619/3619 [==============================] - 2s 455us/step - loss: 0.5423 - accuracy: 3.9721e-04\n",
      "Epoch 123/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5531 - accuracy: 3.7994e-04\n",
      "Epoch 124/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5370 - accuracy: 4.1448e-04\n",
      "Epoch 125/200\n",
      "3619/3619 [==============================] - 2s 434us/step - loss: 0.5292 - accuracy: 4.5766e-04\n",
      "Epoch 126/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5071 - accuracy: 3.9721e-04\n",
      "Epoch 127/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.5527 - accuracy: 3.7131e-04\n",
      "Epoch 128/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5371 - accuracy: 3.8858e-04\n",
      "Epoch 129/200\n",
      "3619/3619 [==============================] - 2s 434us/step - loss: 0.5191 - accuracy: 4.2312e-04\n",
      "Epoch 130/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5025 - accuracy: 3.9721e-04\n",
      "Epoch 131/200\n",
      "3619/3619 [==============================] - 2s 444us/step - loss: 0.5393 - accuracy: 3.7131e-04\n",
      "Epoch 132/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.5062 - accuracy: 4.1448e-04\n",
      "Epoch 133/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5120 - accuracy: 3.8858e-04\n",
      "Epoch 134/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5063 - accuracy: 4.0585e-04\n",
      "Epoch 135/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5298 - accuracy: 3.8858e-04\n",
      "Epoch 136/200\n",
      "3619/3619 [==============================] - 2s 433us/step - loss: 0.5724 - accuracy: 4.0585e-04\n",
      "Epoch 137/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5276 - accuracy: 4.4039e-04\n",
      "Epoch 138/200\n",
      "3619/3619 [==============================] - 2s 456us/step - loss: 0.5294 - accuracy: 3.5404e-04\n",
      "Epoch 139/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.5517 - accuracy: 4.2312e-04\n",
      "Epoch 140/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.5519 - accuracy: 3.5404e-04\n",
      "Epoch 141/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.5238 - accuracy: 4.1448e-04\n",
      "Epoch 142/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.5502 - accuracy: 3.6267e-04\n",
      "Epoch 143/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5119 - accuracy: 3.9721e-04\n",
      "Epoch 144/200\n",
      "3619/3619 [==============================] - 2s 431us/step - loss: 0.5212 - accuracy: 3.7994e-04\n",
      "Epoch 145/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5062 - accuracy: 4.4902e-04\n",
      "Epoch 146/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5186 - accuracy: 4.2312e-04\n",
      "Epoch 147/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.5451 - accuracy: 4.1448e-04\n",
      "Epoch 148/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5466 - accuracy: 4.5766e-04\n",
      "Epoch 149/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.5313 - accuracy: 4.4039e-04\n",
      "Epoch 150/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.5730 - accuracy: 3.1950e-04\n",
      "Epoch 151/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.5170 - accuracy: 4.1448e-04\n",
      "Epoch 152/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.5074 - accuracy: 3.9721e-04\n",
      "Epoch 153/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.5263 - accuracy: 4.1448e-04\n",
      "Epoch 154/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5207 - accuracy: 3.7994e-04\n",
      "Epoch 155/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.5099 - accuracy: 3.7994e-04\n",
      "Epoch 156/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.5193 - accuracy: 3.8858e-04\n",
      "Epoch 157/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.5190 - accuracy: 3.6267e-04\n",
      "Epoch 158/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5233 - accuracy: 4.4039e-04\n",
      "Epoch 159/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5320 - accuracy: 3.8858e-04\n",
      "Epoch 160/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5742 - accuracy: 3.9721e-04\n",
      "Epoch 161/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.5168 - accuracy: 3.7994e-04\n",
      "Epoch 162/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5157 - accuracy: 4.2312e-04\n",
      "Epoch 163/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.5253 - accuracy: 3.9721e-04\n",
      "Epoch 164/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5022 - accuracy: 4.2312e-04\n",
      "Epoch 165/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5266 - accuracy: 3.5404e-04\n",
      "Epoch 166/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5608 - accuracy: 4.1448e-04\n",
      "Epoch 167/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.5218 - accuracy: 4.1448e-04\n",
      "Epoch 168/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5149 - accuracy: 3.7994e-04\n",
      "Epoch 169/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.5175 - accuracy: 3.4540e-04\n",
      "Epoch 170/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5389 - accuracy: 3.9721e-04\n",
      "Epoch 171/200\n",
      "3619/3619 [==============================] - 2s 434us/step - loss: 0.5359 - accuracy: 3.8858e-04\n",
      "Epoch 172/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.5028 - accuracy: 3.5404e-04\n",
      "Epoch 173/200\n",
      "3619/3619 [==============================] - 2s 454us/step - loss: 0.5335 - accuracy: 3.7994e-04\n",
      "Epoch 174/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.5263 - accuracy: 3.8858e-04\n",
      "Epoch 175/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5413 - accuracy: 3.7994e-04\n",
      "Epoch 176/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.5280 - accuracy: 4.1448e-04\n",
      "Epoch 177/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.5094 - accuracy: 4.3175e-04\n",
      "Epoch 178/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5302 - accuracy: 4.1448e-04\n",
      "Epoch 179/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.5477 - accuracy: 3.3677e-04\n",
      "Epoch 180/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.5379 - accuracy: 3.5404e-04\n",
      "Epoch 181/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.5126 - accuracy: 3.8858e-04\n",
      "Epoch 182/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.5154 - accuracy: 4.1448e-04\n",
      "Epoch 183/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.4864 - accuracy: 3.7994e-04\n",
      "Epoch 184/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.5315 - accuracy: 4.2312e-04\n",
      "Epoch 185/200\n",
      "3619/3619 [==============================] - 2s 455us/step - loss: 0.5148 - accuracy: 3.6267e-04\n",
      "Epoch 186/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.5080 - accuracy: 3.5404e-04\n",
      "Epoch 187/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.5378 - accuracy: 3.9721e-04\n",
      "Epoch 188/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.5526 - accuracy: 4.1448e-04\n",
      "Epoch 189/200\n",
      "3619/3619 [==============================] - 2s 433us/step - loss: 0.5016 - accuracy: 3.7994e-04\n",
      "Epoch 190/200\n",
      "3619/3619 [==============================] - 2s 444us/step - loss: 0.5057 - accuracy: 4.0585e-04\n",
      "Epoch 191/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.5335 - accuracy: 4.0585e-04\n",
      "Epoch 192/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5384 - accuracy: 4.1448e-04\n",
      "Epoch 193/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.5258 - accuracy: 3.9721e-04\n",
      "Epoch 194/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5553 - accuracy: 3.8858e-04\n",
      "Epoch 195/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.5179 - accuracy: 3.8858e-04\n",
      "Epoch 196/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.5238 - accuracy: 3.8858e-04\n",
      "Epoch 197/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.5279 - accuracy: 4.2312e-04\n",
      "Epoch 198/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.5377 - accuracy: 3.6267e-04\n",
      "Epoch 199/200\n",
      "3619/3619 [==============================] - 2s 456us/step - loss: 0.5028 - accuracy: 4.0585e-04\n",
      "Epoch 200/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.5068 - accuracy: 3.7131e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c430c040>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the ANN on the training set\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 200, workers=4, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403/403 [==============================] - 0s 273us/step\n",
      "[[ 2.69638872  2.88154786]\n",
      " [ 0.7322979   0.88632513]\n",
      " [ 5.51837778  5.20489792]\n",
      " [ 0.18054152  0.12729438]\n",
      " [ 3.71085691  3.93802885]\n",
      " [ 3.90713096  3.94485059]\n",
      " [ 3.76739287  3.73508224]\n",
      " [ 3.13078403  3.2402449 ]\n",
      " [ 5.09408379  5.24504292]\n",
      " [ 2.91837382  3.07340095]\n",
      " [13.01607895 13.49653498]\n",
      " [ 4.10761166  4.574675  ]\n",
      " [17.2495575  16.1630866 ]\n",
      " [ 9.32838631 10.19401786]\n",
      " [15.48104191 15.72194747]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "#y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)[10:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 2.80%\n"
     ]
    }
   ],
   "source": [
    "len1 = len(y_pred)\n",
    "len2 = np.sum((y_pred.flatten()>8) != (y_test>8))\n",
    "error = len2/len1*100\n",
    "print(f\"Error: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "ann.save('ann_modelH1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(XV1, yV1, test_size = 0.1, random_state = 0)\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# save the scaler\n",
    "import pickle\n",
    "pickle.dump(sc, open('scalerV1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ANN\n",
    "ann = tf.keras.models.Sequential() \n",
    "\n",
    "# adding the input layer and the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=4, activation='relu'))\n",
    "# adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "# adding the third hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='sigmoid'))\n",
    "# adding the output layer, absolute value of the snr\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "#ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the ANN\n",
    "# loss = 'mean_squared_error'\n",
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3619/3619 [==============================] - 2s 425us/step - loss: 6.0651 - accuracy: 2.6769e-04\n",
      "Epoch 2/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 2.4633 - accuracy: 5.2674e-04\n",
      "Epoch 3/200\n",
      "3619/3619 [==============================] - 2s 539us/step - loss: 1.9188 - accuracy: 6.1309e-04\n",
      "Epoch 4/200\n",
      "3619/3619 [==============================] - 2s 444us/step - loss: 1.6844 - accuracy: 5.7855e-04\n",
      "Epoch 5/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 1.5139 - accuracy: 5.6991e-04\n",
      "Epoch 6/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 1.3816 - accuracy: 5.7855e-04\n",
      "Epoch 7/200\n",
      "3619/3619 [==============================] - 2s 444us/step - loss: 1.2944 - accuracy: 6.1309e-04\n",
      "Epoch 8/200\n",
      "3619/3619 [==============================] - 2s 470us/step - loss: 1.2242 - accuracy: 5.6128e-04\n",
      "Epoch 9/200\n",
      "3619/3619 [==============================] - 2s 431us/step - loss: 1.1776 - accuracy: 5.8718e-04\n",
      "Epoch 10/200\n",
      "3619/3619 [==============================] - 2s 468us/step - loss: 1.1279 - accuracy: 6.1309e-04\n",
      "Epoch 11/200\n",
      "3619/3619 [==============================] - 2s 468us/step - loss: 1.0940 - accuracy: 5.9582e-04\n",
      "Epoch 12/200\n",
      "3619/3619 [==============================] - 2s 520us/step - loss: 1.0578 - accuracy: 5.9582e-04\n",
      "Epoch 13/200\n",
      "3619/3619 [==============================] - 2s 510us/step - loss: 1.0272 - accuracy: 5.9582e-04\n",
      "Epoch 14/200\n",
      "3619/3619 [==============================] - 2s 457us/step - loss: 0.9987 - accuracy: 6.1309e-04\n",
      "Epoch 15/200\n",
      "3619/3619 [==============================] - 2s 463us/step - loss: 0.9704 - accuracy: 6.3899e-04\n",
      "Epoch 16/200\n",
      "3619/3619 [==============================] - 2s 431us/step - loss: 0.9457 - accuracy: 6.5626e-04\n",
      "Epoch 17/200\n",
      "3619/3619 [==============================] - 2s 456us/step - loss: 0.9281 - accuracy: 6.6490e-04\n",
      "Epoch 18/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.9055 - accuracy: 6.6490e-04\n",
      "Epoch 19/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.8907 - accuracy: 6.7353e-04\n",
      "Epoch 20/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.8696 - accuracy: 6.3036e-04\n",
      "Epoch 21/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.8553 - accuracy: 6.9080e-04\n",
      "Epoch 22/200\n",
      "3619/3619 [==============================] - 2s 444us/step - loss: 0.8355 - accuracy: 6.3899e-04\n",
      "Epoch 23/200\n",
      "3619/3619 [==============================] - 2s 423us/step - loss: 0.8212 - accuracy: 6.5626e-04\n",
      "Epoch 24/200\n",
      "3619/3619 [==============================] - 2s 434us/step - loss: 0.8074 - accuracy: 7.1671e-04\n",
      "Epoch 25/200\n",
      "3619/3619 [==============================] - 2s 424us/step - loss: 0.7859 - accuracy: 6.9944e-04\n",
      "Epoch 26/200\n",
      "3619/3619 [==============================] - 2s 468us/step - loss: 0.7743 - accuracy: 6.2172e-04\n",
      "Epoch 27/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.7659 - accuracy: 6.5626e-04\n",
      "Epoch 28/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.7486 - accuracy: 6.5626e-04\n",
      "Epoch 29/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.7322 - accuracy: 6.5626e-04\n",
      "Epoch 30/200\n",
      "3619/3619 [==============================] - 2s 425us/step - loss: 0.7298 - accuracy: 6.6490e-04\n",
      "Epoch 31/200\n",
      "3619/3619 [==============================] - 2s 429us/step - loss: 0.7118 - accuracy: 6.9944e-04\n",
      "Epoch 32/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.7011 - accuracy: 6.9944e-04\n",
      "Epoch 33/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.6799 - accuracy: 6.7353e-04\n",
      "Epoch 34/200\n",
      "3619/3619 [==============================] - 2s 424us/step - loss: 0.6755 - accuracy: 6.8217e-04\n",
      "Epoch 35/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.6762 - accuracy: 6.8217e-04\n",
      "Epoch 36/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.6496 - accuracy: 6.7353e-04\n",
      "Epoch 37/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.6451 - accuracy: 6.6490e-04\n",
      "Epoch 38/200\n",
      "3619/3619 [==============================] - 2s 422us/step - loss: 0.6568 - accuracy: 6.3899e-04\n",
      "Epoch 39/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.6468 - accuracy: 6.5626e-04\n",
      "Epoch 40/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.6191 - accuracy: 6.2172e-04\n",
      "Epoch 41/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.6102 - accuracy: 6.4763e-04\n",
      "Epoch 42/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.6110 - accuracy: 6.2172e-04\n",
      "Epoch 43/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.5948 - accuracy: 6.3036e-04\n",
      "Epoch 44/200\n",
      "3619/3619 [==============================] - 2s 434us/step - loss: 0.6156 - accuracy: 6.5626e-04\n",
      "Epoch 45/200\n",
      "3619/3619 [==============================] - 2s 454us/step - loss: 0.5776 - accuracy: 6.3036e-04\n",
      "Epoch 46/200\n",
      "3619/3619 [==============================] - 2s 463us/step - loss: 0.5883 - accuracy: 6.4763e-04\n",
      "Epoch 47/200\n",
      "3619/3619 [==============================] - 2s 478us/step - loss: 0.5696 - accuracy: 6.8217e-04\n",
      "Epoch 48/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.5525 - accuracy: 6.4763e-04\n",
      "Epoch 49/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5623 - accuracy: 6.8217e-04\n",
      "Epoch 50/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.5396 - accuracy: 6.7353e-04\n",
      "Epoch 51/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.5393 - accuracy: 6.9080e-04\n",
      "Epoch 52/200\n",
      "3619/3619 [==============================] - 2s 429us/step - loss: 0.5309 - accuracy: 7.3398e-04\n",
      "Epoch 53/200\n",
      "3619/3619 [==============================] - 2s 429us/step - loss: 0.5524 - accuracy: 6.7353e-04\n",
      "Epoch 54/200\n",
      "3619/3619 [==============================] - 2s 429us/step - loss: 0.5198 - accuracy: 6.8217e-04\n",
      "Epoch 55/200\n",
      "3619/3619 [==============================] - 2s 463us/step - loss: 0.5073 - accuracy: 7.1671e-04\n",
      "Epoch 56/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.5347 - accuracy: 7.6852e-04\n",
      "Epoch 57/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.5155 - accuracy: 7.4261e-04\n",
      "Epoch 58/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.4922 - accuracy: 7.2534e-04\n",
      "Epoch 59/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.5276 - accuracy: 7.3398e-04\n",
      "Epoch 60/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.4785 - accuracy: 6.9080e-04\n",
      "Epoch 61/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.4796 - accuracy: 7.2534e-04\n",
      "Epoch 62/200\n",
      "3619/3619 [==============================] - 2s 426us/step - loss: 0.4785 - accuracy: 7.5125e-04\n",
      "Epoch 63/200\n",
      "3619/3619 [==============================] - 2s 433us/step - loss: 0.4677 - accuracy: 7.0807e-04\n",
      "Epoch 64/200\n",
      "3619/3619 [==============================] - 2s 459us/step - loss: 0.4665 - accuracy: 7.0807e-04\n",
      "Epoch 65/200\n",
      "3619/3619 [==============================] - 2s 463us/step - loss: 0.4872 - accuracy: 7.5125e-04\n",
      "Epoch 66/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.4492 - accuracy: 6.9080e-04\n",
      "Epoch 67/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.4592 - accuracy: 6.9944e-04\n",
      "Epoch 68/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.4553 - accuracy: 7.3398e-04\n",
      "Epoch 69/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.4429 - accuracy: 7.2534e-04\n",
      "Epoch 70/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.4414 - accuracy: 7.0807e-04\n",
      "Epoch 71/200\n",
      "3619/3619 [==============================] - 2s 432us/step - loss: 0.4777 - accuracy: 7.0807e-04\n",
      "Epoch 72/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.4400 - accuracy: 7.5989e-04\n",
      "Epoch 73/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.4292 - accuracy: 7.2534e-04\n",
      "Epoch 74/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.4310 - accuracy: 7.2534e-04\n",
      "Epoch 75/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.4290 - accuracy: 7.5989e-04\n",
      "Epoch 76/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.4315 - accuracy: 7.5125e-04\n",
      "Epoch 77/200\n",
      "3619/3619 [==============================] - 2s 472us/step - loss: 0.4183 - accuracy: 7.3398e-04\n",
      "Epoch 78/200\n",
      "3619/3619 [==============================] - 2s 457us/step - loss: 0.4130 - accuracy: 7.5125e-04\n",
      "Epoch 79/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.4803 - accuracy: 7.5125e-04\n",
      "Epoch 80/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.4327 - accuracy: 7.5989e-04\n",
      "Epoch 81/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.4116 - accuracy: 7.2534e-04\n",
      "Epoch 82/200\n",
      "3619/3619 [==============================] - 2s 444us/step - loss: 0.4524 - accuracy: 7.4261e-04\n",
      "Epoch 83/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.3948 - accuracy: 7.5125e-04\n",
      "Epoch 84/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.4008 - accuracy: 7.4261e-04\n",
      "Epoch 85/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.3947 - accuracy: 7.3398e-04\n",
      "Epoch 86/200\n",
      "3619/3619 [==============================] - 2s 466us/step - loss: 0.4228 - accuracy: 7.2534e-04\n",
      "Epoch 87/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.5104 - accuracy: 7.1671e-04\n",
      "Epoch 88/200\n",
      "3619/3619 [==============================] - 2s 454us/step - loss: 0.4040 - accuracy: 7.6852e-04\n",
      "Epoch 89/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.3862 - accuracy: 7.2534e-04\n",
      "Epoch 90/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.4578 - accuracy: 7.4261e-04\n",
      "Epoch 91/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.3777 - accuracy: 7.2534e-04\n",
      "Epoch 92/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.3950 - accuracy: 7.5989e-04\n",
      "Epoch 93/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.3706 - accuracy: 7.2534e-04\n",
      "Epoch 94/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.3874 - accuracy: 7.1671e-04\n",
      "Epoch 95/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.3640 - accuracy: 7.6852e-04\n",
      "Epoch 96/200\n",
      "3619/3619 [==============================] - 2s 444us/step - loss: 0.4080 - accuracy: 7.5989e-04\n",
      "Epoch 97/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.3959 - accuracy: 7.4261e-04\n",
      "Epoch 98/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.3668 - accuracy: 7.0807e-04\n",
      "Epoch 99/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.3688 - accuracy: 7.5989e-04\n",
      "Epoch 100/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.3815 - accuracy: 8.1170e-04\n",
      "Epoch 101/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.3762 - accuracy: 7.5125e-04\n",
      "Epoch 102/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.3763 - accuracy: 7.8579e-04\n",
      "Epoch 103/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.3582 - accuracy: 7.9443e-04\n",
      "Epoch 104/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.3813 - accuracy: 7.4261e-04\n",
      "Epoch 105/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.3376 - accuracy: 8.2033e-04\n",
      "Epoch 106/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.3727 - accuracy: 7.1671e-04\n",
      "Epoch 107/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.3525 - accuracy: 7.3398e-04\n",
      "Epoch 108/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.3329 - accuracy: 7.9443e-04\n",
      "Epoch 109/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.3876 - accuracy: 7.5989e-04\n",
      "Epoch 110/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.3278 - accuracy: 7.6852e-04\n",
      "Epoch 111/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.3523 - accuracy: 7.9443e-04\n",
      "Epoch 112/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.4017 - accuracy: 8.2033e-04\n",
      "Epoch 113/200\n",
      "3619/3619 [==============================] - 2s 458us/step - loss: 0.3362 - accuracy: 7.8579e-04\n",
      "Epoch 114/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.3442 - accuracy: 8.0306e-04\n",
      "Epoch 115/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.3520 - accuracy: 8.3760e-04\n",
      "Epoch 116/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.3553 - accuracy: 7.7716e-04\n",
      "Epoch 117/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.3486 - accuracy: 7.7716e-04\n",
      "Epoch 118/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.4096 - accuracy: 8.3760e-04\n",
      "Epoch 119/200\n",
      "3619/3619 [==============================] - 2s 442us/step - loss: 0.3274 - accuracy: 8.1170e-04\n",
      "Epoch 120/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.3519 - accuracy: 7.8579e-04\n",
      "Epoch 121/200\n",
      "3619/3619 [==============================] - 2s 434us/step - loss: 0.4397 - accuracy: 8.2897e-04\n",
      "Epoch 122/200\n",
      "3619/3619 [==============================] - 2s 455us/step - loss: 0.3092 - accuracy: 8.7214e-04\n",
      "Epoch 123/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.3177 - accuracy: 8.7214e-04\n",
      "Epoch 124/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.3474 - accuracy: 7.9443e-04\n",
      "Epoch 125/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.3124 - accuracy: 8.2897e-04\n",
      "Epoch 126/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.3488 - accuracy: 8.6351e-04\n",
      "Epoch 127/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.3244 - accuracy: 8.9805e-04\n",
      "Epoch 128/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.3163 - accuracy: 8.9805e-04\n",
      "Epoch 129/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.2982 - accuracy: 8.5487e-04\n",
      "Epoch 130/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.3272 - accuracy: 8.8941e-04\n",
      "Epoch 131/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.2969 - accuracy: 8.8078e-04\n",
      "Epoch 132/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.2976 - accuracy: 9.1532e-04\n",
      "Epoch 133/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.3241 - accuracy: 8.3760e-04\n",
      "Epoch 134/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.3263 - accuracy: 9.2395e-04\n",
      "Epoch 135/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.2965 - accuracy: 9.0668e-04\n",
      "Epoch 136/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.3773 - accuracy: 9.1532e-04\n",
      "Epoch 137/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.4540 - accuracy: 8.8078e-04\n",
      "Epoch 138/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.3453 - accuracy: 8.9805e-04\n",
      "Epoch 139/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.3496 - accuracy: 9.0668e-04\n",
      "Epoch 140/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.2908 - accuracy: 9.1532e-04\n",
      "Epoch 141/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.2980 - accuracy: 9.8440e-04\n",
      "Epoch 142/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.3385 - accuracy: 9.7576e-04\n",
      "Epoch 143/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.3164 - accuracy: 9.3259e-04\n",
      "Epoch 144/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.3047 - accuracy: 9.5849e-04\n",
      "Epoch 145/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.3059 - accuracy: 8.9805e-04\n",
      "Epoch 146/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.3029 - accuracy: 9.2395e-04\n",
      "Epoch 147/200\n",
      "3619/3619 [==============================] - 2s 444us/step - loss: 0.3361 - accuracy: 9.2395e-04\n",
      "Epoch 148/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.2825 - accuracy: 9.5849e-04\n",
      "Epoch 149/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.3602 - accuracy: 9.6713e-04\n",
      "Epoch 150/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.2772 - accuracy: 9.4986e-04\n",
      "Epoch 151/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.3000 - accuracy: 9.2395e-04\n",
      "Epoch 152/200\n",
      "3619/3619 [==============================] - 2s 448us/step - loss: 0.2779 - accuracy: 9.7576e-04\n",
      "Epoch 153/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.3097 - accuracy: 9.8440e-04\n",
      "Epoch 154/200\n",
      "3619/3619 [==============================] - 2s 453us/step - loss: 0.2794 - accuracy: 0.0010\n",
      "Epoch 155/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.3065 - accuracy: 0.0010\n",
      "Epoch 156/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.2895 - accuracy: 0.0010\n",
      "Epoch 157/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.3078 - accuracy: 9.7576e-04\n",
      "Epoch 158/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.2864 - accuracy: 9.5849e-04\n",
      "Epoch 159/200\n",
      "3619/3619 [==============================] - 2s 460us/step - loss: 0.3116 - accuracy: 9.5849e-04\n",
      "Epoch 160/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.2833 - accuracy: 9.9303e-04\n",
      "Epoch 161/200\n",
      "3619/3619 [==============================] - 2s 473us/step - loss: 0.2721 - accuracy: 9.9303e-04\n",
      "Epoch 162/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.2695 - accuracy: 9.4986e-04\n",
      "Epoch 163/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.3190 - accuracy: 9.7576e-04\n",
      "Epoch 164/200\n",
      "3619/3619 [==============================] - 2s 463us/step - loss: 0.2930 - accuracy: 9.4986e-04\n",
      "Epoch 165/200\n",
      "3619/3619 [==============================] - 2s 446us/step - loss: 0.2638 - accuracy: 9.6713e-04\n",
      "Epoch 166/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.2897 - accuracy: 0.0010\n",
      "Epoch 167/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.3059 - accuracy: 0.0010\n",
      "Epoch 168/200\n",
      "3619/3619 [==============================] - 2s 451us/step - loss: 0.3407 - accuracy: 0.0010\n",
      "Epoch 169/200\n",
      "3619/3619 [==============================] - 2s 452us/step - loss: 0.2822 - accuracy: 0.0010\n",
      "Epoch 170/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.2723 - accuracy: 9.9303e-04\n",
      "Epoch 171/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.2788 - accuracy: 9.6713e-04\n",
      "Epoch 172/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.3009 - accuracy: 9.8440e-04\n",
      "Epoch 173/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.3557 - accuracy: 9.7576e-04\n",
      "Epoch 174/200\n",
      "3619/3619 [==============================] - 2s 433us/step - loss: 0.2632 - accuracy: 9.8440e-04\n",
      "Epoch 175/200\n",
      "3619/3619 [==============================] - 2s 441us/step - loss: 0.3053 - accuracy: 9.8440e-04\n",
      "Epoch 176/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.2814 - accuracy: 0.0010\n",
      "Epoch 177/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.2773 - accuracy: 9.9303e-04\n",
      "Epoch 178/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.2836 - accuracy: 0.0010\n",
      "Epoch 179/200\n",
      "3619/3619 [==============================] - 2s 433us/step - loss: 0.2900 - accuracy: 0.0010\n",
      "Epoch 180/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.2859 - accuracy: 0.0010\n",
      "Epoch 181/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.3058 - accuracy: 0.0010\n",
      "Epoch 182/200\n",
      "3619/3619 [==============================] - 2s 435us/step - loss: 0.2590 - accuracy: 0.0010\n",
      "Epoch 183/200\n",
      "3619/3619 [==============================] - 2s 447us/step - loss: 0.3725 - accuracy: 0.0010\n",
      "Epoch 184/200\n",
      "3619/3619 [==============================] - 2s 434us/step - loss: 0.2601 - accuracy: 9.8440e-04\n",
      "Epoch 185/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.2741 - accuracy: 0.0010\n",
      "Epoch 186/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.3909 - accuracy: 0.0010\n",
      "Epoch 187/200\n",
      "3619/3619 [==============================] - 2s 437us/step - loss: 0.4099 - accuracy: 0.0010\n",
      "Epoch 188/200\n",
      "3619/3619 [==============================] - 2s 449us/step - loss: 0.3164 - accuracy: 0.0010\n",
      "Epoch 189/200\n",
      "3619/3619 [==============================] - 2s 436us/step - loss: 0.4065 - accuracy: 0.0010\n",
      "Epoch 190/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.3088 - accuracy: 0.0011\n",
      "Epoch 191/200\n",
      "3619/3619 [==============================] - 2s 424us/step - loss: 0.3074 - accuracy: 0.0010\n",
      "Epoch 192/200\n",
      "3619/3619 [==============================] - 2s 455us/step - loss: 0.3088 - accuracy: 9.9303e-04\n",
      "Epoch 193/200\n",
      "3619/3619 [==============================] - 2s 445us/step - loss: 0.2854 - accuracy: 9.8440e-04\n",
      "Epoch 194/200\n",
      "3619/3619 [==============================] - 2s 430us/step - loss: 0.2925 - accuracy: 0.0010\n",
      "Epoch 195/200\n",
      "3619/3619 [==============================] - 2s 439us/step - loss: 0.3004 - accuracy: 0.0010\n",
      "Epoch 196/200\n",
      "3619/3619 [==============================] - 2s 438us/step - loss: 0.3064 - accuracy: 0.0010\n",
      "Epoch 197/200\n",
      "3619/3619 [==============================] - 2s 443us/step - loss: 0.2881 - accuracy: 9.9303e-04\n",
      "Epoch 198/200\n",
      "3619/3619 [==============================] - 2s 450us/step - loss: 0.3016 - accuracy: 9.5849e-04\n",
      "Epoch 199/200\n",
      "3619/3619 [==============================] - 2s 429us/step - loss: 0.3682 - accuracy: 9.9303e-04\n",
      "Epoch 200/200\n",
      "3619/3619 [==============================] - 2s 440us/step - loss: 0.2944 - accuracy: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c4639090>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the ANN on the training set\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 200, workers=4, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403/403 [==============================] - 0s 286us/step\n",
      "[[ 4.72483921  4.89011872]\n",
      " [ 0.51686001  0.58607411]\n",
      " [ 2.41460609  2.3015468 ]\n",
      " [ 0.37161541  0.33531481]\n",
      " [ 0.5280695   0.55868314]\n",
      " [ 2.36961079  2.32671789]\n",
      " [ 2.77364969  2.66532758]\n",
      " [ 1.93723869  2.00618009]\n",
      " [ 3.18798256  3.24378541]\n",
      " [ 5.53580332  5.29487968]\n",
      " [ 4.41453123  4.57756   ]\n",
      " [ 4.10081005  4.19438302]\n",
      " [ 8.1741991   7.69393088]\n",
      " [ 4.8905549   5.11534798]\n",
      " [10.4428978  10.75656564]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "#y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)[10:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.23%\n"
     ]
    }
   ],
   "source": [
    "len1 = len(y_pred)\n",
    "len2 = np.sum((y_pred.flatten()>8) != (y_test>8))\n",
    "error = len2/len1*100\n",
    "print(f\"Error: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "ann.save('ann_modelV1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all models and test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "modelL1 = load_model('ann_modelL1.h5')\n",
    "modelH1 = load_model('ann_modelH1.h5')\n",
    "modelV1 = load_model('ann_modelV1.h5')\n",
    "\n",
    "# load the scaler\n",
    "import pickle\n",
    "scalerL1 = pickle.load(open('scalerL1.pkl', 'rb'))\n",
    "scalerH1 = pickle.load(open('scalerH1.pkl', 'rb'))\n",
    "scalerV1 = pickle.load(open('scalerV1.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phurailatpamhemantakumar/anaconda3/envs/ler/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "modelL1.save('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_output_net(idx, params):\n",
    "\n",
    "    mass_1 = np.array(params['mass_1'][idx])\n",
    "    mass_2 = np.array(params['mass_2'][idx])\n",
    "    luminosity_distance = np.array(params['luminosity_distance'][idx])\n",
    "    theta_jn = np.array(params['theta_jn'][idx])\n",
    "    psi = np.array(params['psi'][idx])\n",
    "    geocent_time = np.array(params['geocent_time'][idx])\n",
    "    ra = np.array(params['ra'][idx])\n",
    "    dec = np.array(params['dec'][idx])\n",
    "    \n",
    "    detector_tensor = gwsnr.detector_tensor_list\n",
    "    snr_halfscaled = np.array(gwsnr.snr_partialsacaled_list)\n",
    "    ratio_arr = gwsnr.ratio_arr\n",
    "    mtot_arr = gwsnr.mtot_arr\n",
    "    \n",
    "    size = len(mass_1)\n",
    "    len_ = len(detector_tensor)\n",
    "    mtot = mass_1 + mass_2\n",
    "    ratio = mass_2 / mass_1\n",
    "    # get array of antenna response\n",
    "    Fp, Fc = antenna_response_array(ra, dec, geocent_time, psi, detector_tensor)\n",
    "\n",
    "    Mc = ((mass_1 * mass_2) ** (3 / 5)) / ((mass_1 + mass_2) ** (1 / 5))\n",
    "    eta = mass_1 * mass_2/(mass_1 + mass_2)**2.\n",
    "    A1 = Mc ** (5.0 / 6.0)\n",
    "    ci_2 = np.cos(theta_jn) ** 2\n",
    "    ci_param = ((1 + np.cos(theta_jn) ** 2) / 2) ** 2\n",
    "    \n",
    "    size = len(mass_1)\n",
    "    snr_half_ = np.zeros((len_,size))\n",
    "    d_eff = np.zeros((len_,size))\n",
    "\n",
    "    # loop over the detectors\n",
    "    for j in range(len_):\n",
    "        # loop over the parameter points\n",
    "        for i in range(size):\n",
    "            snr_half_coeff = snr_halfscaled[j]\n",
    "            snr_half_[j,i] = cubic_spline_interpolator2d(mtot[i], ratio[i], snr_half_coeff, mtot_arr, ratio_arr)\n",
    "            d_eff[j,i] =luminosity_distance[i] / np.sqrt(\n",
    "                    Fp[j,i]**2 * ci_param[i] + Fc[j,i]**2 * ci_2[i]\n",
    "                )\n",
    "\n",
    "    #amp0\n",
    "    amp0 =  A1 / d_eff\n",
    "\n",
    "    # get spin parameters\n",
    "    a_1 = np.array(params['a_1'][idx])\n",
    "    a_2 = np.array(params['a_2'][idx])\n",
    "    tilt_1 = np.array(params['tilt_1'][idx])\n",
    "    tilt_2 = np.array(params['tilt_2'][idx])\n",
    "\n",
    "    # effective spin\n",
    "    chi_eff = (mass_1 * a_1 * np.cos(tilt_1) + mass_2 * a_2 * np.cos(tilt_2)) / (mass_1 + mass_2)\n",
    "\n",
    "    # input data\n",
    "    L1 = np.vstack([snr_half_[0], amp0[0], eta, chi_eff]).T\n",
    "    H1 = np.vstack([snr_half_[1], amp0[1], eta, chi_eff]).T\n",
    "    V1 = np.vstack([snr_half_[2], amp0[2], eta, chi_eff]).T    \n",
    "\n",
    "    X = np.array([L1, H1, V1])\n",
    "\n",
    "    # output data\n",
    "    # get L1 snr for y train \n",
    "    y = np.sqrt(params['L1'][idx]**2 + params['H1'][idx]**2 + params['V1'][idx]**2)\n",
    "\n",
    "    return(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating new data\n",
    "from ler.rates import LeR\n",
    "ler = LeR(verbose=False, snr_type='inner_product', waveform_approximant=\"IMRPhenomXPHM\", spin_zero=False, spin_precession=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unlensed params will be store in ./ler_data/unlensed_param.json\n",
      "chosen batch size = 50000 with total size = 50000\n",
      "There will be 1 batche(s)\n",
      "Batch no. 1\n",
      "sampling gw source params...\n",
      "calculating snrs...\n",
      "solving SNR with inner product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 46375/46375 [01:10<00:00, 657.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving all unlensed_params in ./ler_data/unlensed_param.json...\n"
     ]
    }
   ],
   "source": [
    "size = 50000\n",
    "unlensed_params = ler.unlensed_cbc_statistics(size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, Y_ = input_output_net(np.arange(size), unlensed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_output_netANN(x_array):\n",
    "    x = scalerL1.transform(x_array[0])\n",
    "    yL1 = modelL1.predict(x)\n",
    "    x = scalerH1.transform(x_array[1])\n",
    "    yH1 = modelH1.predict(x)\n",
    "    x = scalerV1.transform(x_array[2])\n",
    "    yV1 = modelV1.predict(x)\n",
    "    y = np.sqrt(yL1**2 + yH1**2 + yV1**2)\n",
    "    return(x_array,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 0s 273us/step\n",
      "1563/1563 [==============================] - 0s 274us/step\n",
      "1563/1563 [==============================] - 0s 263us/step\n"
     ]
    }
   ],
   "source": [
    "_, snrANN =input_output_netANN(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "1440\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = snrANN.flatten()\n",
    "y_test = Y_\n",
    "hist_ = y_pred-y_test\n",
    "print(len(hist_))\n",
    "idx = (y_test>4) & (y_test<10)\n",
    "hist_ = hist_[idx]\n",
    "#hist_ = hist_[abs(hist_)<5.]\n",
    "print(len(hist_))\n",
    "plt.figure(figsize=(4,4)) \n",
    "plt.hist(hist_, bins=30, histtype='step', density=True)\n",
    "plt.xlim(-5,5)\n",
    "plt.xlabel('snr_ml and snr_inner_product difference')\n",
    "plt.ylabel('pdf')\n",
    "plt.grid(alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.13%\n"
     ]
    }
   ],
   "source": [
    "len1 = len(y_pred)\n",
    "len2 = np.sum((y_pred>8) != (y_test>8))\n",
    "error = len2/len1*100\n",
    "print(f\"Error: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49725    52]\n",
      " [   11   212]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99874"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix((y_test>8), (y_pred>8))\n",
    "print(cm)\n",
    "accuracy_score((y_test>8), (y_pred>8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.15850353  5.37186566]\n",
      " [ 5.92633295  4.90961826]\n",
      " [ 5.1957407   4.98641388]\n",
      " [ 4.82793283  6.81152986]\n",
      " [ 8.04278278  8.43912883]\n",
      " [ 3.9978323   4.20524464]\n",
      " [ 8.20208931  7.78337252]\n",
      " [ 4.30030012  4.13608912]\n",
      " [ 4.84817839  5.06148307]\n",
      " [ 5.4472084   4.87020935]\n",
      " [ 4.67050409  4.16562381]\n",
      " [ 5.00163841  5.57452582]\n",
      " [ 4.45889044  4.64078328]\n",
      " [ 4.47838306  4.61870046]\n",
      " [11.78038025 11.81251126]]\n"
     ]
    }
   ],
   "source": [
    "#y_pred = (y_pred > 0.5)\n",
    "idx = (y_test>4) & (y_pred<12)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)[idx][10:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating new data\n",
    "from ler.rates import LeR\n",
    "ler = LeR(npool=4, event_type = 'BNS', mtot_max=14, z_max = 2.0, verbose=False, snr_type='inner_product', waveform_approximant=\"IMRPhenomXPHM\", spin_zero=False, spin_precession=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unlensed params will be store in ./ler_data/unlensed_bns_ann_test.json\n",
      "chosen batch size = 50000 with total size = 50000\n",
      "There will be 1 batche(s)\n",
      "Batch no. 1\n",
      "sampling gw source params...\n",
      "calculating snrs...\n",
      "solving SNR with inner product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 50000/50000 [10:22<00:00, 80.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving all unlensed_params in ./ler_data/unlensed_bns_ann_test.json...\n"
     ]
    }
   ],
   "source": [
    "size = 50000\n",
    "unlensed_params = ler.unlensed_cbc_statistics(size=size, output_jsonfile='unlensed_bns_ann_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_json\n\u001b[1;32m      2\u001b[0m unlensed_params \u001b[38;5;241m=\u001b[39m load_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mler_data/unlensed_bns_ann_test.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m X_, Y_ \u001b[38;5;241m=\u001b[39m input_output_net(\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marange(size), unlensed_params)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from ler.utils import load_json\n",
    "unlensed_params = load_json('ler_data/unlensed_bns_ann_test.json')\n",
    "\n",
    "X_, Y_ = input_output_net(np.arange(size), unlensed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
