{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNR finder ANN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from scipy.optimize import curve_fit\n",
    "from ler.utils import add_dict_values, append_json, get_param_from_json, load_json, save_json\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from gwsnr import antenna_response_array, cubic_spline_interpolator2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to generate new data to test the model\n",
    "\n",
    "# # generating astrophysical data for testing using `ler` package\n",
    "# from ler.rates import LeR\n",
    "# from ler.utils import get_param_from_json\n",
    "\n",
    "# ler = LeR(verbose=False, snr_type='inner_product', waveform_approximant=\"IMRPhenomXPHM\", spin_zero=False, spin_precession=True, z_max=5)\n",
    "\n",
    "# size_ = 50000\n",
    "# ler.batch_size = 50000\n",
    "# ler.unlensed_cbc_statistics(size=size_, output_jsonfile='unlensed_param_testing.json', resume=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Interpolator will be generated for L1 detector at ./interpolator_pickle/L1/partialSNR_dict_1.pickle\n",
      "Interpolator will be generated for H1 detector at ./interpolator_pickle/H1/partialSNR_dict_1.pickle\n",
      "Interpolator will be generated for V1 detector at ./interpolator_pickle/V1/partialSNR_dict_1.pickle\n",
      "Please be patient while the interpolator is generated\n",
      "Generating interpolator for ['L1', 'H1', 'V1'] detectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "interpolation for each mass_ratios: 100%|███████████████████████████| 50/50 [03:44<00:00,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chosen GWSNR initialization parameters:\n",
      "\n",
      "npool:  4\n",
      "snr type:  ann\n",
      "waveform approximant:  IMRPhenomXPHM\n",
      "sampling frequency:  2048.0\n",
      "minimum frequency (fmin):  20.0\n",
      "mtot=mass1+mass2\n",
      "min(mtot):  2.0\n",
      "max(mtot) (with the given fmin=20.0): 184.98599853446768\n",
      "detectors:  ['L1', 'H1', 'V1']\n",
      "psds:  [PowerSpectralDensity(psd_file='None', asd_file='/Users/phurailatpamhemantakumar/anaconda3/envs/ler/lib/python3.10/site-packages/bilby/gw/detector/noise_curves/aLIGO_O4_high_asd.txt'), PowerSpectralDensity(psd_file='None', asd_file='/Users/phurailatpamhemantakumar/anaconda3/envs/ler/lib/python3.10/site-packages/bilby/gw/detector/noise_curves/aLIGO_O4_high_asd.txt'), PowerSpectralDensity(psd_file='/Users/phurailatpamhemantakumar/anaconda3/envs/ler/lib/python3.10/site-packages/bilby/gw/detector/noise_curves/AdV_psd.txt', asd_file='None')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# let's generate IMRPhenomD (spinless) interpolartor for the snr_half (refer to gwsnr documentation)\n",
    "# One of the training input is half_snr\n",
    "from gwsnr import GWSNR\n",
    "gwsnr = GWSNR(snr_type='ann', waveform_approximant='IMRPhenomXPHM', ifos=['L1', 'H1','V1'], ann_partialscaled_approximant='IMRPhenomXPHM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input-Output generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_output(idx, params):\n",
    "    \"\"\"\n",
    "        Function to generate input and output data for the neural network\n",
    "\n",
    "        Parameters:\n",
    "        idx: index of the parameter points\n",
    "        params: dictionary of parameter points\n",
    "            params.keys() = ['mass_1', 'mass_2', 'luminosity_distance', 'theta_jn', 'psi', 'geocent_time', 'ra', 'dec', 'a_1', 'a_2', 'tilt_1', 'tilt_2', 'L1']\n",
    "\n",
    "        Returns:\n",
    "        X: input data, [snr_half_[0], amp0[0], eta, chi_eff, theta_jn]\n",
    "        y: output data, [L1]\n",
    "    \"\"\"\n",
    "\n",
    "    mass_1 = np.array(params['mass_1'])[idx]\n",
    "    mass_2 = np.array(params['mass_2'])[idx]\n",
    "    luminosity_distance = np.array(params['luminosity_distance'])[idx]\n",
    "    theta_jn = np.array(params['theta_jn'])[idx]\n",
    "    psi = np.array(params['psi'])[idx]\n",
    "    geocent_time = np.array(params['geocent_time'])[idx]\n",
    "    ra = np.array(params['ra'])[idx]\n",
    "    dec = np.array(params['dec'])[idx]\n",
    "    \n",
    "    detector_tensor = gwsnr.detector_tensor_list\n",
    "    snr_halfscaled = np.array(gwsnr.snr_partialsacaled_list)\n",
    "    ratio_arr = gwsnr.ratio_arr\n",
    "    mtot_arr = gwsnr.mtot_arr\n",
    "    \n",
    "    size = len(mass_1)\n",
    "    len_ = len(detector_tensor)\n",
    "    mtot = mass_1 + mass_2\n",
    "    ratio = mass_2 / mass_1\n",
    "    # get array of antenna response\n",
    "    Fp, Fc = antenna_response_array(ra, dec, geocent_time, psi, detector_tensor)\n",
    "\n",
    "    Mc = ((mass_1 * mass_2) ** (3 / 5)) / ((mass_1 + mass_2) ** (1 / 5))\n",
    "    eta = mass_1 * mass_2/(mass_1 + mass_2)**2.\n",
    "    A1 = Mc ** (5.0 / 6.0)\n",
    "    ci_2 = np.cos(theta_jn) ** 2\n",
    "    ci_param = ((1 + np.cos(theta_jn) ** 2) / 2) ** 2\n",
    "    \n",
    "    size = len(mass_1)\n",
    "    snr_half_ = np.zeros((len_,size))\n",
    "    d_eff = np.zeros((len_,size))\n",
    "\n",
    "    # loop over the detectors\n",
    "    for j in range(len_):\n",
    "        # loop over the parameter points\n",
    "        for i in range(size):\n",
    "            snr_half_coeff = snr_halfscaled[j]\n",
    "            snr_half_[j,i] = cubic_spline_interpolator2d(mtot[i], ratio[i], snr_half_coeff, mtot_arr, ratio_arr)\n",
    "            d_eff[j,i] =luminosity_distance[i] / np.sqrt(\n",
    "                    Fp[j,i]**2 * ci_param[i] + Fc[j,i]**2 * ci_2[i]\n",
    "                )\n",
    "\n",
    "    #amp0\n",
    "    amp0 =  A1 / d_eff\n",
    "\n",
    "    # get spin parameters\n",
    "    a_1 = np.array(params['a_1'])[idx]\n",
    "    a_2 = np.array(params['a_2'])[idx]\n",
    "    tilt_1 = np.array(params['tilt_1'])[idx]\n",
    "    tilt_2 = np.array(params['tilt_2'])[idx]\n",
    "\n",
    "    # effective spin\n",
    "    chi_eff = (mass_1 * a_1 * np.cos(tilt_1) + mass_2 * a_2 * np.cos(tilt_2)) / (mass_1 + mass_2)\n",
    "\n",
    "\n",
    "    # input data\n",
    "    XL1 = np.vstack([snr_half_[0], amp0[0], eta, chi_eff, theta_jn]).T\n",
    "    XH1 = np.vstack([snr_half_[1], amp0[1], eta, chi_eff, theta_jn]).T\n",
    "    XV1 = np.vstack([snr_half_[2], amp0[2], eta, chi_eff, theta_jn]).T\n",
    "\n",
    "    # output data\n",
    "    # get snr for y train\n",
    "    yL1 = np.array(params['L1'])[idx]\n",
    "    yH1 = np.array(params['H1'])[idx]\n",
    "    yV1 = np.array(params['V1'])[idx]\n",
    "    yNET = np.sqrt(yL1**2 + yH1**2 + yV1**2)\n",
    "\n",
    "    return(XL1, yL1, XH1, yH1, XV1, yV1, yNET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For L1 detector\n",
    "\n",
    "### Get all necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size before SNR cut: 428819\n",
      "size after SNR cut: 417189\n"
     ]
    }
   ],
   "source": [
    "# these are pre-generated datas\n",
    "# join all dictionaries into one\n",
    "# the naming of data files are based on what you have saved. Refer to 'training_data_generation_ann.ipynb' to see how the data is generated with `ler` package and saved.\n",
    "unlensed_params = get_param_from_json(\"snr_L1.json\")\n",
    "unlensed_params3 = get_param_from_json(\"joint_new_optsnr2.json\")\n",
    "unlensed_params4 = get_param_from_json(\"joint_new_optsnr3.json\")\n",
    "unlensed_params5 = get_param_from_json(\"joint_new_optsnr4.json\")\n",
    "unlensed_params6 = get_param_from_json(\"joint_new_optsnr5.json\")\n",
    "unlensed_params7 = get_param_from_json(\"joint_new_optsnr6.json\")\n",
    "unlensed_params8 = get_param_from_json(\"joint_new_optsnr_uniform.json\")\n",
    "\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params3)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params4)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params5)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params6)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params7)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params8)\n",
    "del unlensed_params8\n",
    "del unlensed_params3, unlensed_params4, unlensed_params5, unlensed_params6, unlensed_params7\n",
    "print(f\"size before SNR cut: {len(unlensed_params['L1'])}\")\n",
    "# set SNR cut\n",
    "idx_constrain = unlensed_params['L1']<100\n",
    "for key, value in unlensed_params.items():\n",
    "    unlensed_params[key] = value[idx_constrain]\n",
    "\n",
    "print(f\"size after SNR cut: {len(unlensed_params['L1'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417189, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_ = len(unlensed_params['L1'])\n",
    "idx = np.arange(len_)\n",
    "# randomize the train set\n",
    "idx = np.random.permutation(idx)\n",
    "XL1, yL1, _, _, _, _,_ = input_output(idx, unlensed_params)\n",
    "np.shape(XL1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is expected to have larger error in the sparse region of the input data, e.g. $\\eta<0.2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(XL1, yL1, test_size = 0.1, random_state = 0)\n",
    "\n",
    "# Uncomment the following if you have not generated the scaler\n",
    "\n",
    "# feature scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# save the scaler\n",
    "pickle.dump(sc, open('scalerL1_final.pkl', 'wb'))\n",
    "\n",
    "# # Uncomment the following if you have already generated the scaler\n",
    "\n",
    "# # load the scaler\n",
    "# scalerL1 = pickle.load(open('scalerL1_final.pkl', 'rb'))\n",
    "# sc = scalerL1\n",
    "# X_train = sc.transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 360us/step - accuracy: 0.0000e+00 - loss: 64.5272\n",
      "Epoch 2/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 5.4456e-06 - loss: 5.5053\n",
      "Epoch 3/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 8.8220e-06 - loss: 5.2864\n",
      "Epoch 4/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 366us/step - accuracy: 1.2095e-05 - loss: 5.2766\n",
      "Epoch 5/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348us/step - accuracy: 2.0237e-05 - loss: 4.9760\n",
      "Epoch 6/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 343us/step - accuracy: 1.8278e-05 - loss: 4.9457\n",
      "Epoch 7/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 338us/step - accuracy: 8.8141e-06 - loss: 5.0208\n",
      "Epoch 8/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 344us/step - accuracy: 7.2609e-06 - loss: 5.1035\n",
      "Epoch 9/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 9.7776e-06 - loss: 4.9122\n",
      "Epoch 10/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 8.4241e-06 - loss: 5.0820\n",
      "Epoch 11/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348us/step - accuracy: 4.6557e-06 - loss: 5.0250\n",
      "Epoch 12/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 7.4229e-06 - loss: 4.8512\n",
      "Epoch 13/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 6.9836e-06 - loss: 4.8024\n",
      "Epoch 14/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 3.5421e-06 - loss: 4.8818\n",
      "Epoch 15/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 1.0061e-05 - loss: 4.9095\n",
      "Epoch 16/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 342us/step - accuracy: 9.9262e-06 - loss: 4.9284\n",
      "Epoch 17/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 5.0073e-06 - loss: 5.0761\n",
      "Epoch 18/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348us/step - accuracy: 1.1017e-05 - loss: 4.7668\n",
      "Epoch 19/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 351us/step - accuracy: 6.0268e-06 - loss: 4.8438\n",
      "Epoch 20/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 1.6040e-05 - loss: 4.7890\n",
      "Epoch 21/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 1.3895e-05 - loss: 4.7343\n",
      "Epoch 22/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 4.0416e-06 - loss: 4.7715\n",
      "Epoch 23/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 351us/step - accuracy: 2.3325e-05 - loss: 4.7861\n",
      "Epoch 24/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 2.4734e-05 - loss: 4.9478\n",
      "Epoch 25/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 9.8395e-06 - loss: 4.8322\n",
      "Epoch 26/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 393us/step - accuracy: 1.7171e-05 - loss: 4.8330\n",
      "Epoch 27/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 1.6005e-05 - loss: 4.7801\n",
      "Epoch 28/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 1.2126e-05 - loss: 4.7505\n",
      "Epoch 29/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 2.4736e-05 - loss: 4.9167\n",
      "Epoch 30/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 9.0202e-06 - loss: 4.7505\n",
      "Epoch 31/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 9.3741e-06 - loss: 4.8379\n",
      "Epoch 32/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361us/step - accuracy: 4.8586e-06 - loss: 4.8571\n",
      "Epoch 33/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 1.8042e-05 - loss: 4.7758\n",
      "Epoch 34/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 2.6123e-05 - loss: 4.8688\n",
      "Epoch 35/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 2.2453e-05 - loss: 4.8624\n",
      "Epoch 36/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 2.3364e-05 - loss: 4.7282\n",
      "Epoch 37/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 343us/step - accuracy: 9.4092e-06 - loss: 4.6540\n",
      "Epoch 38/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 1.1793e-05 - loss: 4.8679\n",
      "Epoch 39/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 343us/step - accuracy: 2.7526e-05 - loss: 4.7226\n",
      "Epoch 40/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 3.6128e-05 - loss: 4.8024\n",
      "Epoch 41/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 342us/step - accuracy: 5.0668e-06 - loss: 4.8792\n",
      "Epoch 42/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 376us/step - accuracy: 1.3207e-05 - loss: 4.8058\n",
      "Epoch 43/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 1.9167e-05 - loss: 4.7825\n",
      "Epoch 44/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 1.5569e-05 - loss: 4.8248\n",
      "Epoch 45/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 1.8497e-05 - loss: 4.8527\n",
      "Epoch 46/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 1.7708e-05 - loss: 4.7736\n",
      "Epoch 47/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 2.4553e-05 - loss: 4.7811\n",
      "Epoch 48/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 8.6780e-06 - loss: 4.8000\n",
      "Epoch 49/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 3.7789e-06 - loss: 4.6494\n",
      "Epoch 50/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 2.7801e-05 - loss: 4.7640\n",
      "Epoch 51/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 2.5683e-06 - loss: 4.6758\n",
      "Epoch 52/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 7.8933e-06 - loss: 5.0225\n",
      "Epoch 53/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 2.9839e-05 - loss: 4.5980\n",
      "Epoch 54/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 363us/step - accuracy: 2.6110e-05 - loss: 4.8596\n",
      "Epoch 55/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360us/step - accuracy: 1.8154e-05 - loss: 4.7605\n",
      "Epoch 56/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360us/step - accuracy: 1.5889e-05 - loss: 4.6685\n",
      "Epoch 57/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 369us/step - accuracy: 6.9516e-06 - loss: 4.7801\n",
      "Epoch 58/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 367us/step - accuracy: 1.2350e-05 - loss: 4.6869\n",
      "Epoch 59/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 399us/step - accuracy: 1.7595e-05 - loss: 4.7250\n",
      "Epoch 60/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 363us/step - accuracy: 2.4832e-05 - loss: 4.6351\n",
      "Epoch 61/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 365us/step - accuracy: 2.6160e-05 - loss: 4.7139\n",
      "Epoch 62/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 1.1751e-05 - loss: 4.8279\n",
      "Epoch 63/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 366us/step - accuracy: 1.9509e-05 - loss: 4.7198\n",
      "Epoch 64/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 376us/step - accuracy: 9.0496e-06 - loss: 4.7191\n",
      "Epoch 65/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 374us/step - accuracy: 9.2118e-06 - loss: 4.7443\n",
      "Epoch 66/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 367us/step - accuracy: 1.5021e-05 - loss: 4.6894\n",
      "Epoch 67/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360us/step - accuracy: 3.4456e-05 - loss: 4.7507\n",
      "Epoch 68/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 367us/step - accuracy: 1.3770e-05 - loss: 4.6873\n",
      "Epoch 69/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 370us/step - accuracy: 6.3598e-06 - loss: 4.7698\n",
      "Epoch 70/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360us/step - accuracy: 9.7280e-06 - loss: 4.6265\n",
      "Epoch 71/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 368us/step - accuracy: 1.7729e-05 - loss: 4.9024\n",
      "Epoch 72/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 376us/step - accuracy: 1.1153e-05 - loss: 4.7209\n",
      "Epoch 73/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 378us/step - accuracy: 6.2122e-06 - loss: 4.7405\n",
      "Epoch 74/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 364us/step - accuracy: 2.3931e-05 - loss: 4.6738\n",
      "Epoch 75/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 366us/step - accuracy: 1.4653e-05 - loss: 4.7910\n",
      "Epoch 76/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 372us/step - accuracy: 1.3287e-05 - loss: 4.7694\n",
      "Epoch 77/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361us/step - accuracy: 2.0747e-05 - loss: 4.7200\n",
      "Epoch 78/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 365us/step - accuracy: 2.2578e-05 - loss: 4.8144\n",
      "Epoch 79/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371us/step - accuracy: 1.7740e-05 - loss: 4.6355\n",
      "Epoch 80/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 1.2523e-05 - loss: 4.6416\n",
      "Epoch 81/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 3.7156e-05 - loss: 4.7911\n",
      "Epoch 82/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 2.8253e-05 - loss: 4.6433\n",
      "Epoch 83/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 2.1519e-05 - loss: 4.8067\n",
      "Epoch 84/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 368us/step - accuracy: 1.4771e-05 - loss: 4.7634\n",
      "Epoch 85/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 374us/step - accuracy: 2.4498e-05 - loss: 4.7347\n",
      "Epoch 86/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 392us/step - accuracy: 1.1966e-05 - loss: 4.7187\n",
      "Epoch 87/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 375us/step - accuracy: 2.2301e-05 - loss: 4.7508\n",
      "Epoch 88/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 366us/step - accuracy: 2.0775e-05 - loss: 4.7098\n",
      "Epoch 89/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 394us/step - accuracy: 5.8186e-06 - loss: 4.7019\n",
      "Epoch 90/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 368us/step - accuracy: 2.0881e-05 - loss: 4.7003\n",
      "Epoch 91/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 362us/step - accuracy: 2.6090e-05 - loss: 4.7895\n",
      "Epoch 92/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361us/step - accuracy: 1.0049e-05 - loss: 4.7630\n",
      "Epoch 93/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361us/step - accuracy: 3.3032e-05 - loss: 4.8429\n",
      "Epoch 94/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 1.5365e-05 - loss: 4.6622\n",
      "Epoch 95/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 363us/step - accuracy: 2.5965e-05 - loss: 4.6853\n",
      "Epoch 96/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 366us/step - accuracy: 2.2626e-05 - loss: 4.7835\n",
      "Epoch 97/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361us/step - accuracy: 2.4557e-05 - loss: 4.8429\n",
      "Epoch 98/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 1.4782e-05 - loss: 4.5912\n",
      "Epoch 99/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 392us/step - accuracy: 1.8594e-05 - loss: 4.7415\n",
      "Epoch 100/100\n",
      "\u001b[1m11734/11734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 362us/step - accuracy: 2.7443e-05 - loss: 4.7747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3438df0a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following if you have already trained the model\n",
    "\n",
    "# initialize the ANN\n",
    "ann = tf.keras.models.Sequential() \n",
    "\n",
    "# adding the input layer and the first hidden layer\n",
    "# units=5, where 5 is the number of neurons in the first input layer\n",
    "ann.add(tf.keras.layers.Dense(units=5, activation='relu'))\n",
    "# adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "# adding the third hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='sigmoid'))\n",
    "# adding the output layer, absolute value of the snr\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "# compile the ANN\n",
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "# train the ANN on the training set\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Uncomment the following if you have not trained the model\n",
    "\n",
    "# Save the model to a file\n",
    "ann.save('ann_modelL1_final.h5')\n",
    "modelL1 = ann\n",
    "\n",
    "# # Uncomment the following if you have already generated the model\n",
    "\n",
    "# # load the model\n",
    "# from tensorflow.keras.models import load_model\n",
    "# modelL1 = load_model('ann_modelL1_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "[[16.46255302 15.36925853]\n",
      " [ 7.34299326  8.1631879 ]\n",
      " [18.40270805 19.32192079]\n",
      " [ 4.46133804  4.77382202]\n",
      " [13.76112938 14.52608943]\n",
      " [10.88520241 11.17061064]\n",
      " [26.74387932 27.36483974]\n",
      " [ 3.37854934  2.72201387]\n",
      " [ 4.46126747  4.30502408]\n",
      " [ 3.76576853  3.08507739]\n",
      " [ 3.33378768  3.29667046]\n",
      " [ 4.21110964  3.96505829]\n",
      " [ 1.69420433  1.24720302]\n",
      " [ 3.82559896  2.41829633]\n",
      " [11.03242683 11.02986875]]\n"
     ]
    }
   ],
   "source": [
    "# left: predicted snr, right: actual snr\n",
    "y_pred = modelL1.predict(X_test)\n",
    "#y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)[10:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 3.89%\n"
     ]
    }
   ],
   "source": [
    "# calculate the error\n",
    "len1 = len(y_pred)\n",
    "len2 = np.sum((y_pred.flatten()>8) != (y_test>8))\n",
    "error = len2/len1*100\n",
    "print(f\"Error: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with astrophysical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "[[49832   105]\n",
      " [    4    59]]\n",
      "Accuracy: 99.782%\n"
     ]
    }
   ],
   "source": [
    "# Get the data. This data is generated using `ler` package.\n",
    "unlensed_params = get_param_from_json(\"ler_data/unlensed_param_testing.json\")\n",
    "X_,Y_,_,_,_,_,_ = input_output(np.arange(len(unlensed_params['L1'])), unlensed_params)\n",
    "scalerL1 = pickle.load(open('scalerL1_final.pkl', 'rb'))\n",
    "X_ = scalerL1.transform(X_)\n",
    "\n",
    "modelL1 = load_model('ann_modelL1_final.h5')\n",
    "y_pred_ = modelL1.predict(X_).flatten()\n",
    "y_test_ = Y_\n",
    "cm = confusion_matrix((y_test_>8), ((y_pred_)>8))\n",
    "print(cm)\n",
    "accuracy = accuracy_score((y_test_>8), (y_pred_>8))*100\n",
    "print(f\"Accuracy: {accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope: 0.0001, intercept: -0.0075\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to create error ajustment\n",
    "\n",
    "# do linear fitting of the error y_pred-y_test\n",
    "def func(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "idx = (y_pred_>4) & (y_pred_<10)\n",
    "idx = idx & (y_test_!=0)\n",
    "popt, pcov = curve_fit(func, y_pred_[idx], y_pred_[idx]-y_test_[idx])\n",
    "print(f\"slope: {popt[0]:.4f}, intercept: {popt[1]:.4f}\")\n",
    "\n",
    "adjustment_dict = {'slope': popt[0], 'intercept': popt[1]}\n",
    "\n",
    "# save json\n",
    "save_json('error_adjustmentL1_final.json', adjustment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "[[49832   105]\n",
      " [    4    59]]\n",
      "Accuracy (after error ajustment): 99.782%\n"
     ]
    }
   ],
   "source": [
    "# load json\n",
    "adjustment_dict = load_json('error_adjustmentL1_final.json')\n",
    "a = adjustment_dict['slope']\n",
    "b = adjustment_dict['intercept']\n",
    "\n",
    "y_pred_ = modelL1.predict(X_).flatten()\n",
    "y_pred_ = y_pred_-(a*y_pred_ + b)\n",
    "y_test_ = Y_\n",
    "cm = confusion_matrix((y_test_>8), ((y_pred_)>8))\n",
    "print(cm)\n",
    "accuracy = accuracy_score((y_test_>8), (y_pred_>8))*100\n",
    "print(f\"Accuracy (after error ajustment): {accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size before SNR cut: 425469\n",
      "size after SNR cut: 413822\n"
     ]
    }
   ],
   "source": [
    "# the naming of data files are based on what you have saved. Refer to 'training_data_generation_ann.ipynb' to see how the data is generated with `ler` package and saved.\n",
    "\n",
    "# joint all dict\n",
    "unlensed_params = get_param_from_json(\"snr_H1.json\")\n",
    "unlensed_params3 = get_param_from_json(\"joint_new_optsnr2.json\")\n",
    "unlensed_params4 = get_param_from_json(\"joint_new_optsnr3.json\")\n",
    "unlensed_params5 = get_param_from_json(\"joint_new_optsnr4.json\")\n",
    "unlensed_params6 = get_param_from_json(\"joint_new_optsnr5.json\")\n",
    "unlensed_params7 = get_param_from_json(\"joint_new_optsnr6.json\")\n",
    "unlensed_params8 = get_param_from_json(\"joint_new_optsnr_uniform.json\")\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params3)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params4)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params5)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params6)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params7)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params8)\n",
    "del unlensed_params8\n",
    "del unlensed_params3, unlensed_params4, unlensed_params5, unlensed_params6, unlensed_params7\n",
    "print(f\"size before SNR cut: {len(unlensed_params['H1'])}\")\n",
    "# set SNR cut\n",
    "# this is optimise the ANN by ignoring the high SNR\n",
    "idx_constrain = unlensed_params['H1']<100\n",
    "for key, value in unlensed_params.items():\n",
    "    unlensed_params[key] = value[idx_constrain]\n",
    "\n",
    "print(f\"size after SNR cut: {len(unlensed_params['H1'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413822, 5)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_ = len(unlensed_params['H1'])\n",
    "idx = np.arange(len_)\n",
    "# randomize the train set\n",
    "idx = np.random.permutation(idx)\n",
    "_, _, XH1, yH1, _, _, _ = input_output(idx, unlensed_params)\n",
    "np.shape(XH1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(XH1, yH1, test_size = 0.1, random_state = 0)\n",
    "\n",
    "# Uncomment the following if you have not generated the scaler\n",
    "\n",
    "# feature scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# save the scaler\n",
    "pickle.dump(sc, open('scalerH1_final.pkl', 'wb'))\n",
    "\n",
    "# # Uncomment the following if you have already generated the scaler\n",
    "\n",
    "# # load the scaler\n",
    "# scalerH1 = pickle.load(open('scalerH1_final.pkl', 'rb'))\n",
    "# sc = scalerH1\n",
    "# X_train = sc.transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 338us/step - accuracy: 1.8018e-06 - loss: 81.5036\n",
      "Epoch 2/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 330us/step - accuracy: 1.4028e-05 - loss: 6.0598\n",
      "Epoch 3/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 343us/step - accuracy: 3.9449e-06 - loss: 5.3143\n",
      "Epoch 4/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 337us/step - accuracy: 1.4624e-06 - loss: 5.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 363us/step - accuracy: 6.1660e-06 - loss: 5.1094\n",
      "Epoch 6/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 370us/step - accuracy: 0.0000e+00 - loss: 5.0545\n",
      "Epoch 7/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 338us/step - accuracy: 0.0000e+00 - loss: 4.7952\n",
      "Epoch 8/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 341us/step - accuracy: 0.0000e+00 - loss: 4.9421\n",
      "Epoch 9/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348us/step - accuracy: 1.5122e-05 - loss: 4.8460\n",
      "Epoch 10/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 5.2802e-06 - loss: 4.9224\n",
      "Epoch 11/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 0.0000e+00 - loss: 5.0360\n",
      "Epoch 12/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 368us/step - accuracy: 6.1221e-06 - loss: 4.9050\n",
      "Epoch 13/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 2.2289e-06 - loss: 5.0311\n",
      "Epoch 14/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 5.1504e-07 - loss: 4.8461\n",
      "Epoch 15/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 1.4820e-05 - loss: 5.0626\n",
      "Epoch 16/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 5.9103e-06 - loss: 4.7978\n",
      "Epoch 17/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 1.6141e-05 - loss: 4.8741\n",
      "Epoch 18/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 345us/step - accuracy: 4.8241e-06 - loss: 4.8853\n",
      "Epoch 19/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 3.9896e-06 - loss: 4.9178\n",
      "Epoch 20/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 8.5965e-06 - loss: 4.7931\n",
      "Epoch 21/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 1.5961e-08 - loss: 4.9891\n",
      "Epoch 22/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 2.1334e-06 - loss: 4.9049\n",
      "Epoch 23/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 9.1989e-07 - loss: 4.7283\n",
      "Epoch 24/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 5.3696e-06 - loss: 4.8957\n",
      "Epoch 25/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348us/step - accuracy: 0.0000e+00 - loss: 4.7703\n",
      "Epoch 26/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 6.1611e-07 - loss: 4.9091\n",
      "Epoch 27/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 363us/step - accuracy: 3.8470e-07 - loss: 4.8566\n",
      "Epoch 28/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 392us/step - accuracy: 1.6442e-06 - loss: 4.7319\n",
      "Epoch 29/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 351us/step - accuracy: 1.7634e-06 - loss: 4.8461\n",
      "Epoch 30/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 0.0000e+00 - loss: 4.7785\n",
      "Epoch 31/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 1.8119e-06 - loss: 4.7501\n",
      "Epoch 32/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 0.0000e+00 - loss: 4.8571\n",
      "Epoch 33/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 1.1568e-06 - loss: 4.9458\n",
      "Epoch 34/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 6.4332e-06 - loss: 4.8312\n",
      "Epoch 35/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361us/step - accuracy: 1.1875e-06 - loss: 4.7979\n",
      "Epoch 36/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 6.0164e-07 - loss: 4.8620\n",
      "Epoch 37/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 6.2841e-06 - loss: 4.7903\n",
      "Epoch 38/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 363us/step - accuracy: 9.1730e-07 - loss: 4.7769\n",
      "Epoch 39/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 369us/step - accuracy: 5.2232e-07 - loss: 4.6857\n",
      "Epoch 40/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 370us/step - accuracy: 1.1519e-06 - loss: 4.8585\n",
      "Epoch 41/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 0.0000e+00 - loss: 4.7398\n",
      "Epoch 42/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 1.7357e-06 - loss: 4.7788\n",
      "Epoch 43/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361us/step - accuracy: 1.8580e-06 - loss: 4.8046\n",
      "Epoch 44/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 368us/step - accuracy: 8.4967e-07 - loss: 4.9296\n",
      "Epoch 45/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 364us/step - accuracy: 1.4732e-06 - loss: 4.8277\n",
      "Epoch 46/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360us/step - accuracy: 0.0000e+00 - loss: 4.7674\n",
      "Epoch 47/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 2.5258e-06 - loss: 4.7329\n",
      "Epoch 48/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 380us/step - accuracy: 8.2277e-06 - loss: 4.8143\n",
      "Epoch 49/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371us/step - accuracy: 1.9078e-06 - loss: 4.6760\n",
      "Epoch 50/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 365us/step - accuracy: 2.2001e-06 - loss: 4.6657\n",
      "Epoch 51/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 4.1855e-06 - loss: 4.7839\n",
      "Epoch 52/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361us/step - accuracy: 3.8515e-06 - loss: 4.7498\n",
      "Epoch 53/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 368us/step - accuracy: 1.6408e-06 - loss: 4.7082\n",
      "Epoch 54/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360us/step - accuracy: 1.3549e-06 - loss: 4.9061\n",
      "Epoch 55/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 0.0000e+00 - loss: 4.8240\n",
      "Epoch 56/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 2.4650e-06 - loss: 4.7087\n",
      "Epoch 57/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 0.0000e+00 - loss: 4.7640\n",
      "Epoch 58/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 4.8894e-06 - loss: 4.7484\n",
      "Epoch 59/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 356us/step - accuracy: 1.2588e-06 - loss: 4.7644\n",
      "Epoch 60/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 3.2902e-06 - loss: 4.7566\n",
      "Epoch 61/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 0.0000e+00 - loss: 4.6977\n",
      "Epoch 62/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 7.2541e-07 - loss: 4.6921\n",
      "Epoch 63/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 3.9951e-06 - loss: 4.7549\n",
      "Epoch 64/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 356us/step - accuracy: 2.7397e-06 - loss: 4.8166\n",
      "Epoch 65/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 9.5450e-06 - loss: 4.6893\n",
      "Epoch 66/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 3.0693e-06 - loss: 4.7810\n",
      "Epoch 67/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 9.8135e-07 - loss: 4.8451\n",
      "Epoch 68/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 356us/step - accuracy: 0.0000e+00 - loss: 4.6270\n",
      "Epoch 69/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 1.4740e-05 - loss: 4.7274\n",
      "Epoch 70/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 1.2263e-05 - loss: 4.7358\n",
      "Epoch 71/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 2.6860e-06 - loss: 4.7454\n",
      "Epoch 72/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 3.6521e-06 - loss: 4.7361\n",
      "Epoch 73/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 356us/step - accuracy: 1.9285e-05 - loss: 4.8201\n",
      "Epoch 74/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 351us/step - accuracy: 3.4539e-06 - loss: 4.7316\n",
      "Epoch 75/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 356us/step - accuracy: 9.1437e-06 - loss: 4.7525\n",
      "Epoch 76/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 1.4551e-06 - loss: 4.7930\n",
      "Epoch 77/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 362us/step - accuracy: 3.8061e-06 - loss: 4.7219\n",
      "Epoch 78/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 381us/step - accuracy: 4.2794e-06 - loss: 4.8081\n",
      "Epoch 79/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 3.7972e-06 - loss: 4.7481\n",
      "Epoch 80/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 2.2160e-06 - loss: 4.6472\n",
      "Epoch 81/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 2.1257e-06 - loss: 4.6941\n",
      "Epoch 82/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 5.8374e-06 - loss: 4.8267\n",
      "Epoch 83/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 6.0172e-06 - loss: 4.6460\n",
      "Epoch 84/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 6.0221e-06 - loss: 4.6687\n",
      "Epoch 85/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 5.7071e-06 - loss: 4.6677\n",
      "Epoch 86/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 1.4962e-05 - loss: 4.6269\n",
      "Epoch 87/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 1.3232e-05 - loss: 4.7545\n",
      "Epoch 88/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 356us/step - accuracy: 3.6721e-06 - loss: 4.7026\n",
      "Epoch 89/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 1.2507e-05 - loss: 4.6958\n",
      "Epoch 90/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371us/step - accuracy: 3.5061e-06 - loss: 4.7990\n",
      "Epoch 91/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 378us/step - accuracy: 3.0140e-05 - loss: 4.7825\n",
      "Epoch 92/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 1.1994e-05 - loss: 4.7327\n",
      "Epoch 93/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371us/step - accuracy: 7.6030e-06 - loss: 4.8363\n",
      "Epoch 94/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 368us/step - accuracy: 1.4705e-06 - loss: 4.5797\n",
      "Epoch 95/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 383us/step - accuracy: 6.9083e-06 - loss: 4.6062\n",
      "Epoch 96/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360us/step - accuracy: 3.8029e-06 - loss: 4.7663\n",
      "Epoch 97/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361us/step - accuracy: 5.0593e-06 - loss: 4.5752\n",
      "Epoch 98/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360us/step - accuracy: 8.4021e-06 - loss: 4.6472\n",
      "Epoch 99/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 363us/step - accuracy: 5.6637e-06 - loss: 4.7700\n",
      "Epoch 100/100\n",
      "\u001b[1m11639/11639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360us/step - accuracy: 1.0727e-05 - loss: 4.6902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x34861d660>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following if you have already trained the model\n",
    "\n",
    "# initialize the ANN\n",
    "ann = tf.keras.models.Sequential() \n",
    "\n",
    "# adding the input layer and the first hidden layer\n",
    "# units=5, where 5 is the number of neurons in the first input layer\n",
    "ann.add(tf.keras.layers.Dense(units=5, activation='relu'))\n",
    "# adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "# adding the third hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='sigmoid'))\n",
    "# adding the output layer, absolute value of the snr\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "# compile the ANN\n",
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "# train the ANN on the training set\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Uncomment the following if you have not trained the model\n",
    "\n",
    "# Save the model to a file\n",
    "ann.save('ann_modelH1_final.h5')\n",
    "modelH1 = ann\n",
    "\n",
    "# # Uncomment the following if you have already generated the model\n",
    "\n",
    "# # load the model\n",
    "# modelH1 = load_model('ann_modelH1_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1294/1294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "[[ 2.25415564  1.87825041]\n",
      " [ 3.34012222  3.53847344]\n",
      " [ 9.60850906  9.43302369]\n",
      " [ 5.97652388  5.13859978]\n",
      " [19.10847282 13.83949988]\n",
      " [14.54276085 15.00340638]\n",
      " [ 6.51977968  6.65599621]\n",
      " [ 4.68445778  4.85796818]\n",
      " [ 6.26563549  6.70824177]\n",
      " [ 1.70905924  1.80254243]\n",
      " [63.90172195 59.5720179 ]\n",
      " [ 3.55520535  4.06904557]\n",
      " [ 4.11082363  4.00315261]\n",
      " [ 2.85332918  2.92882747]\n",
      " [ 2.48083162  2.58145873]]\n"
     ]
    }
   ],
   "source": [
    "# left: predicted snr, right: actual snr\n",
    "y_pred = modelH1.predict(X_test)\n",
    "#y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)[10:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 4.11%\n"
     ]
    }
   ],
   "source": [
    "# calculate the error\n",
    "len1 = len(y_pred)\n",
    "len2 = np.sum((y_pred.flatten()>8) != (y_test>8))\n",
    "error = len2/len1*100\n",
    "print(f\"Error: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with astrophysical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step\n",
      "[[49900    45]\n",
      " [    8    47]]\n",
      "Accuracy: 99.894%\n"
     ]
    }
   ],
   "source": [
    "# Get the data. This data is generated using `ler` package.\n",
    "unlensed_params = get_param_from_json(\"ler_data/unlensed_param_testing.json\")\n",
    "_, _, X_, Y_, _, _, _ = input_output(np.arange(len(unlensed_params['H1'])), unlensed_params)\n",
    "scalerH1 = pickle.load(open('scalerH1_final.pkl', 'rb'))\n",
    "X_ = scalerH1.transform(X_)\n",
    "\n",
    "modelH1 = load_model('ann_modelH1_final.h5')\n",
    "y_pred_ = modelH1.predict(X_).flatten()\n",
    "y_test_ = Y_\n",
    "cm = confusion_matrix((y_test_>8), ((y_pred_)>8))\n",
    "print(cm)\n",
    "accuracy = accuracy_score((y_test_>8), (y_pred_>8))*100\n",
    "print(f\"Accuracy: {accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope: -0.0039, intercept: 0.0193\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to create error ajustment\n",
    "\n",
    "# do linear fitting of the error y_pred-y_test\n",
    "def func(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "idx = (y_pred_>4) & (y_pred_<10)\n",
    "idx = idx & (y_test_!=0)\n",
    "popt, pcov = curve_fit(func, y_pred_[idx], y_pred_[idx]-y_test_[idx])\n",
    "print(f\"slope: {popt[0]:.4f}, intercept: {popt[1]:.4f}\")\n",
    "\n",
    "adjustment_dict = {'slope': popt[0], 'intercept': popt[1]}\n",
    "# save json\n",
    "save_json('error_adjustmentH1_final.json', adjustment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "[[49900    45]\n",
      " [    8    47]]\n",
      "Accuracy (after error ajustment): 99.894%\n"
     ]
    }
   ],
   "source": [
    "# load json\n",
    "adjustment_dict = load_json('error_adjustmentH1_final.json')\n",
    "a = adjustment_dict['slope']\n",
    "b = adjustment_dict['intercept']\n",
    "\n",
    "y_pred_ = modelH1.predict(X_).flatten()\n",
    "y_pred_ = y_pred_-(a*y_pred_ + b)\n",
    "y_test_ = Y_\n",
    "cm = confusion_matrix((y_test_>8), ((y_pred_)>8))\n",
    "print(cm)\n",
    "accuracy = accuracy_score((y_test_>8), (y_pred_>8))*100\n",
    "print(f\"Accuracy (after error ajustment): {accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size before SNR cut: 409441\n",
      "size after SNR cut: 400502\n"
     ]
    }
   ],
   "source": [
    "# these are pre-generated datas\n",
    "# join all dictionaries into one\n",
    "# the naming of data files are based on what you have saved. Refer to 'training_data_generation_ann.ipynb' to see how the data is generated with `ler` package and saved.\n",
    "unlensed_params = get_param_from_json(\"snr_V1.json\")\n",
    "unlensed_params3 = get_param_from_json(\"joint_new_optsnr2.json\")\n",
    "unlensed_params4 = get_param_from_json(\"joint_new_optsnr3.json\")\n",
    "unlensed_params5 = get_param_from_json(\"joint_new_optsnr4.json\")\n",
    "unlensed_params6 = get_param_from_json(\"joint_new_optsnr5.json\")\n",
    "unlensed_params7 = get_param_from_json(\"joint_new_optsnr6.json\")\n",
    "unlensed_params8 = get_param_from_json(\"joint_new_optsnr_uniform.json\")\n",
    "\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params3)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params4)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params5)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params6)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params7)\n",
    "unlensed_params = add_dict_values(unlensed_params, unlensed_params8)\n",
    "del unlensed_params8\n",
    "del unlensed_params3, unlensed_params4, unlensed_params5, unlensed_params6, unlensed_params7\n",
    "print(f\"size before SNR cut: {len(unlensed_params['V1'])}\")\n",
    "# set SNR cut\n",
    "idx_constrain = unlensed_params['V1']<100\n",
    "for key, value in unlensed_params.items():\n",
    "    unlensed_params[key] = value[idx_constrain]\n",
    "\n",
    "print(f\"size after SNR cut: {len(unlensed_params['V1'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400502, 5)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_ = len(unlensed_params['V1'])\n",
    "idx = np.arange(len_)\n",
    "# randomize the train set\n",
    "idx = np.random.permutation(idx)\n",
    "_, _, _, _, XV1, yV1,_ = input_output(idx, unlensed_params)\n",
    "np.shape(XV1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(XV1, yV1, test_size = 0.1, random_state = 0)\n",
    "\n",
    "# Uncomment the following if you have not generated the scaler\n",
    "\n",
    "# feature scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# save the scaler\n",
    "pickle.dump(sc, open('scalerV1_final.pkl', 'wb'))\n",
    "\n",
    "# # Uncomment the following if you have already generated the scaler\n",
    "\n",
    "# # load the scaler\n",
    "# scalerV1 = pickle.load(open('scalerV1_final.pkl', 'rb'))\n",
    "# sc = scalerV1\n",
    "# X_train = sc.transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 351us/step - accuracy: 2.6724e-05 - loss: 54.9475\n",
      "Epoch 2/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 1.8967e-06 - loss: 5.0122\n",
      "Epoch 3/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 332us/step - accuracy: 9.8649e-06 - loss: 4.8508\n",
      "Epoch 4/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 336us/step - accuracy: 1.2657e-05 - loss: 4.9597\n",
      "Epoch 5/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 333us/step - accuracy: 0.0000e+00 - loss: 4.6671\n",
      "Epoch 6/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 336us/step - accuracy: 7.8731e-06 - loss: 4.5809\n",
      "Epoch 7/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 342us/step - accuracy: 2.2992e-05 - loss: 4.6862\n",
      "Epoch 8/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 334us/step - accuracy: 8.5719e-06 - loss: 4.7661\n",
      "Epoch 9/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 338us/step - accuracy: 1.5589e-05 - loss: 4.7302\n",
      "Epoch 10/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 341us/step - accuracy: 8.2987e-06 - loss: 4.7268\n",
      "Epoch 11/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 7.3318e-07 - loss: 4.7132\n",
      "Epoch 12/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 1.4815e-05 - loss: 4.6952\n",
      "Epoch 13/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 5.4748e-06 - loss: 4.5275\n",
      "Epoch 14/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 343us/step - accuracy: 1.1908e-05 - loss: 4.5629\n",
      "Epoch 15/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 344us/step - accuracy: 1.6633e-06 - loss: 4.8291\n",
      "Epoch 16/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 1.3975e-05 - loss: 4.5567\n",
      "Epoch 17/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 1.2884e-06 - loss: 4.6322\n",
      "Epoch 18/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 6.9506e-06 - loss: 4.5431\n",
      "Epoch 19/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 356us/step - accuracy: 2.7948e-06 - loss: 4.5659\n",
      "Epoch 20/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 1.3957e-06 - loss: 4.6853\n",
      "Epoch 21/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 5.9961e-06 - loss: 4.7025\n",
      "Epoch 22/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348us/step - accuracy: 4.1798e-07 - loss: 4.4670\n",
      "Epoch 23/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 351us/step - accuracy: 0.0000e+00 - loss: 4.5848\n",
      "Epoch 24/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 0.0000e+00 - loss: 4.5033\n",
      "Epoch 25/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 364us/step - accuracy: 0.0000e+00 - loss: 4.6024\n",
      "Epoch 26/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 372us/step - accuracy: 0.0000e+00 - loss: 4.6761\n",
      "Epoch 27/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 0.0000e+00 - loss: 4.5290\n",
      "Epoch 28/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 0.0000e+00 - loss: 4.5717\n",
      "Epoch 29/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 7.7821e-06 - loss: 4.6039\n",
      "Epoch 30/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 363us/step - accuracy: 1.2443e-05 - loss: 4.5823\n",
      "Epoch 31/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 362us/step - accuracy: 3.0517e-05 - loss: 4.5468\n",
      "Epoch 32/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 368us/step - accuracy: 4.7361e-05 - loss: 4.5084\n",
      "Epoch 33/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 5.9793e-05 - loss: 4.4953\n",
      "Epoch 34/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 5.4981e-05 - loss: 4.4217\n",
      "Epoch 35/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 363us/step - accuracy: 3.8696e-05 - loss: 4.4460\n",
      "Epoch 36/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 375us/step - accuracy: 3.2369e-05 - loss: 4.3049\n",
      "Epoch 37/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 4.2556e-05 - loss: 4.4770\n",
      "Epoch 38/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 6.8111e-05 - loss: 4.4041\n",
      "Epoch 39/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 368us/step - accuracy: 3.9970e-05 - loss: 4.4234\n",
      "Epoch 40/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361us/step - accuracy: 3.4490e-05 - loss: 4.2646\n",
      "Epoch 41/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 384us/step - accuracy: 2.0565e-05 - loss: 4.4392\n",
      "Epoch 42/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 1.4591e-05 - loss: 4.5041\n",
      "Epoch 43/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 351us/step - accuracy: 9.2041e-06 - loss: 4.5339\n",
      "Epoch 44/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360us/step - accuracy: 4.1314e-05 - loss: 4.4239\n",
      "Epoch 45/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 363us/step - accuracy: 4.1721e-05 - loss: 4.4153\n",
      "Epoch 46/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 372us/step - accuracy: 5.3475e-05 - loss: 4.4087\n",
      "Epoch 47/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 362us/step - accuracy: 3.3379e-05 - loss: 4.3001\n",
      "Epoch 48/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 351us/step - accuracy: 6.3531e-05 - loss: 4.2387\n",
      "Epoch 49/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 6.4312e-05 - loss: 4.3709\n",
      "Epoch 50/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 2.3675e-05 - loss: 4.2461\n",
      "Epoch 51/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 356us/step - accuracy: 5.2405e-05 - loss: 4.5270\n",
      "Epoch 52/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 5.2231e-05 - loss: 4.3885\n",
      "Epoch 53/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 379us/step - accuracy: 6.7633e-05 - loss: 4.3682\n",
      "Epoch 54/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 362us/step - accuracy: 7.3844e-05 - loss: 4.2614\n",
      "Epoch 55/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 391us/step - accuracy: 7.7995e-05 - loss: 4.4613\n",
      "Epoch 56/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 334us/step - accuracy: 5.4130e-05 - loss: 4.3427\n",
      "Epoch 57/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 398us/step - accuracy: 4.4553e-05 - loss: 4.3025\n",
      "Epoch 58/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 440us/step - accuracy: 7.4875e-05 - loss: 4.3685\n",
      "Epoch 59/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 471us/step - accuracy: 7.4341e-05 - loss: 4.3342\n",
      "Epoch 60/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 460us/step - accuracy: 7.7815e-05 - loss: 4.2258\n",
      "Epoch 61/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 478us/step - accuracy: 7.7610e-05 - loss: 4.4864\n",
      "Epoch 62/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 431us/step - accuracy: 5.2013e-05 - loss: 4.4025\n",
      "Epoch 63/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 433us/step - accuracy: 6.8415e-05 - loss: 4.3891\n",
      "Epoch 64/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 390us/step - accuracy: 6.0204e-05 - loss: 4.2545\n",
      "Epoch 65/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 340us/step - accuracy: 5.5650e-05 - loss: 4.3795\n",
      "Epoch 66/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 5.4010e-05 - loss: 4.2643\n",
      "Epoch 67/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 342us/step - accuracy: 7.3133e-05 - loss: 4.2525\n",
      "Epoch 68/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 341us/step - accuracy: 5.5326e-05 - loss: 4.3955\n",
      "Epoch 69/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 342us/step - accuracy: 7.4238e-05 - loss: 4.2887\n",
      "Epoch 70/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 341us/step - accuracy: 6.4969e-05 - loss: 4.2543\n",
      "Epoch 71/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 341us/step - accuracy: 6.8443e-05 - loss: 4.3608\n",
      "Epoch 72/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 342us/step - accuracy: 6.8031e-05 - loss: 4.3121\n",
      "Epoch 73/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 6.5342e-05 - loss: 4.2914\n",
      "Epoch 74/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 344us/step - accuracy: 6.6155e-05 - loss: 4.1942\n",
      "Epoch 75/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 6.2259e-05 - loss: 4.2673\n",
      "Epoch 76/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 6.1317e-05 - loss: 4.3277\n",
      "Epoch 77/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 345us/step - accuracy: 5.3818e-05 - loss: 4.1869\n",
      "Epoch 78/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 8.3596e-05 - loss: 4.2413\n",
      "Epoch 79/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 4.9303e-05 - loss: 4.1962\n",
      "Epoch 80/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 7.3100e-05 - loss: 4.3274\n",
      "Epoch 81/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 7.7056e-05 - loss: 4.3074\n",
      "Epoch 82/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 6.1758e-05 - loss: 4.2286\n",
      "Epoch 83/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 5.8248e-05 - loss: 4.3563\n",
      "Epoch 84/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 2.8201e-05 - loss: 4.2791\n",
      "Epoch 85/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 6.1223e-05 - loss: 4.4405\n",
      "Epoch 86/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 6.0760e-05 - loss: 4.2014\n",
      "Epoch 87/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 343us/step - accuracy: 6.1578e-05 - loss: 4.4975\n",
      "Epoch 88/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 5.5927e-05 - loss: 4.2679\n",
      "Epoch 89/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 8.3340e-05 - loss: 4.2675\n",
      "Epoch 90/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 5.6632e-05 - loss: 4.5622\n",
      "Epoch 91/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 6.2234e-05 - loss: 4.1801\n",
      "Epoch 92/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 7.9901e-05 - loss: 4.3347\n",
      "Epoch 93/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 5.8099e-05 - loss: 4.2545\n",
      "Epoch 94/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 6.1876e-05 - loss: 4.2449\n",
      "Epoch 95/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348us/step - accuracy: 8.3926e-05 - loss: 4.3351\n",
      "Epoch 96/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348us/step - accuracy: 6.9630e-05 - loss: 4.2252\n",
      "Epoch 97/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 7.1689e-05 - loss: 4.2973\n",
      "Epoch 98/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 6.4544e-05 - loss: 4.2379\n",
      "Epoch 99/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 343us/step - accuracy: 8.6531e-05 - loss: 4.2136\n",
      "Epoch 100/100\n",
      "\u001b[1m11265/11265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 337us/step - accuracy: 5.4742e-05 - loss: 4.0928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x372d1c850>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following if you have already trained the model\n",
    "\n",
    "# initialize the ANN\n",
    "ann = tf.keras.models.Sequential() \n",
    "\n",
    "# adding the input layer and the first hidden layer\n",
    "# units=5, where 5 is the number of neurons in the first input layer\n",
    "ann.add(tf.keras.layers.Dense(units=5, activation='relu'))\n",
    "# adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "# adding the third hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='sigmoid'))\n",
    "# adding the output layer, absolute value of the snr\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "# compile the ANN\n",
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "# train the ANN on the training set\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Uncomment the following if you have not trained the model\n",
    "\n",
    "# Save the model to a file\n",
    "ann.save('ann_modelV1_final.h5')\n",
    "modelV1 = ann\n",
    "\n",
    "# # Uncomment the following if you have already generated the model\n",
    "\n",
    "# # load the model\n",
    "# from tensorflow.keras.models import load_model\n",
    "# modelV1 = load_model('ann_modelV1_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240us/step\n",
      "[[ 2.74133778  2.49808277]\n",
      " [ 5.26034546  4.78553512]\n",
      " [ 3.25269341  2.8022612 ]\n",
      " [ 5.23806095  4.74671099]\n",
      " [ 1.86369276  1.56265661]\n",
      " [ 8.36128235  8.59268207]\n",
      " [ 1.94900537  1.56980042]\n",
      " [ 2.48335981  3.19269323]\n",
      " [ 6.12845612  6.03677146]\n",
      " [ 3.78313708  2.99391856]\n",
      " [ 5.29105759  5.07915485]\n",
      " [13.35671425 13.56670004]\n",
      " [ 4.39101124  4.72982666]\n",
      " [ 0.90243912  0.54252684]\n",
      " [ 4.83383942  4.92850756]]\n"
     ]
    }
   ],
   "source": [
    "# left: predicted snr, right: actual snr\n",
    "y_pred = modelV1.predict(X_test)\n",
    "#y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)[10:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 2.11%\n"
     ]
    }
   ],
   "source": [
    "# calculate the error\n",
    "len1 = len(y_pred)\n",
    "len2 = np.sum((y_pred.flatten()>8) != (y_test>8))\n",
    "error = len2/len1*100\n",
    "print(f\"Error: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with astrophysical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "[[49952    18]\n",
      " [    4    26]]\n",
      "Accuracy: 99.956%\n"
     ]
    }
   ],
   "source": [
    "# Get the data. This data is generated using `ler` package.\n",
    "unlensed_params = get_param_from_json(\"ler_data/unlensed_param_testing.json\")\n",
    "_,_,_,_,X_,Y_,_ = input_output(np.arange(len(unlensed_params['V1'])), unlensed_params)\n",
    "scalerV1 = pickle.load(open('scalerV1_final.pkl', 'rb'))\n",
    "X_ = scalerV1.transform(X_)\n",
    "\n",
    "modelV1 = load_model('ann_modelV1_final.h5')\n",
    "y_pred_ = modelV1.predict(X_).flatten()\n",
    "y_test_ = Y_\n",
    "cm = confusion_matrix((y_test_>8), ((y_pred_)>8))\n",
    "print(cm)\n",
    "accuracy = accuracy_score((y_test_>8), (y_pred_>8))*100\n",
    "print(f\"Accuracy: {accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope: -0.0383, intercept: 0.5121\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to create error ajustment\n",
    "\n",
    "# do linear fitting of the error y_pred-y_test\n",
    "def func(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "idx = (y_pred_>4) & (y_pred_<10)\n",
    "idx = idx & (y_test_!=0)\n",
    "popt, pcov = curve_fit(func, y_pred_[idx], y_pred_[idx]-y_test_[idx])\n",
    "print(f\"slope: {popt[0]:.4f}, intercept: {popt[1]:.4f}\")\n",
    "\n",
    "adjustment_dict = {'slope': popt[0], 'intercept': popt[1]}\n",
    "# save json\n",
    "save_json('error_adjustmentV1_final.json', adjustment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step\n",
      "[[49956    14]\n",
      " [    5    25]]\n",
      "Accuracy (after error ajustment): 99.962%\n"
     ]
    }
   ],
   "source": [
    "# load json\n",
    "adjustment_dict = load_json('error_adjustmentV1_final.json')\n",
    "a = adjustment_dict['slope']\n",
    "b = adjustment_dict['intercept']\n",
    "\n",
    "y_pred_ = modelV1.predict(X_).flatten()\n",
    "y_pred_ = y_pred_-(a*y_pred_ + b)\n",
    "y_test_ = Y_\n",
    "cm = confusion_matrix((y_test_>8), ((y_pred_)>8))\n",
    "print(cm)\n",
    "accuracy = accuracy_score((y_test_>8), (y_pred_>8))*100\n",
    "print(f\"Accuracy (after error ajustment): {accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1, H1, V1, NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the models, scalers and correction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# load the ANN models\n",
    "modelL1 = load_model('ann_modelL1_final.h5')\n",
    "modelH1 = load_model('ann_modelH1_final.h5')\n",
    "modelV1 = load_model('ann_modelV1_final.h5')\n",
    "\n",
    "# load the feature scaler\n",
    "scalerL1 = pickle.load(open('scalerL1_final.pkl', 'rb'))\n",
    "scalerH1 = pickle.load(open('scalerH1_final.pkl', 'rb'))\n",
    "scalerV1 = pickle.load(open('scalerV1_final.pkl', 'rb'))\n",
    "\n",
    "# load the correction slope and intercept\n",
    "correctionL1 = load_json('error_adjustmentL1_final.json')\n",
    "correctionH1 = load_json('error_adjustmentH1_final.json')\n",
    "correctionV1 = load_json('error_adjustmentV1_final.json')\n",
    "aL1 = correctionL1['slope']\n",
    "bL1 = correctionL1['intercept']\n",
    "aH1 = correctionH1['slope']\n",
    "bH1 = correctionH1['intercept']\n",
    "aV1 = correctionV1['slope']\n",
    "bV1 = correctionV1['intercept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlensed_params = get_param_from_json(\"ler_data/unlensed_param_testing.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "XL1, yL1, XH1, yH1, XV1, yV1, yNET = input_output(np.arange(len(unlensed_params['optimal_snr_net'])), unlensed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_snr_net_ANN(XL1, XH1, XV1):\n",
    "    \"\"\"\n",
    "        Function to predict the network SNR using the ANN models\n",
    "\n",
    "        Parameters:\n",
    "        XL1: input data for L1, [snr_half_[0], amp0[0], eta, chi_eff, theta_jn]\n",
    "        XH1: input data for H1, [snr_half_[1], amp0[1], eta, chi_eff, theta_jn]\n",
    "        XV1: input data for V1, [snr_half_[2], amp0[2], eta, chi_eff, theta_jn]\n",
    "\n",
    "        Returns:\n",
    "        y: network SNR\n",
    "    \"\"\"\n",
    "    x = scalerL1.transform(XL1)\n",
    "    yL1 = modelL1.predict(x)\n",
    "    yL1 = yL1 - (aL1*yL1 + bL1)\n",
    "    x = scalerH1.transform(XH1)\n",
    "    yH1 = modelH1.predict(x)\n",
    "    yH1 = yH1 - (aH1*yH1 + bH1)\n",
    "    x = scalerV1.transform(XV1)\n",
    "    yV1 = modelV1.predict(x)\n",
    "    yV1 = yV1 - (aV1*yV1 + bV1)\n",
    "    y = np.sqrt(yL1**2 + yH1**2 + yV1**2)\n",
    "\n",
    "    mass_1 = np.array(unlensed_params['mass_1'])\n",
    "    mass_2 = np.array(unlensed_params['mass_2'])\n",
    "    mtot = mass_1 + mass_2\n",
    "    y[mtot>gwsnr.mtot_max] = 0.\n",
    "\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.3222325, 1.9176006, 1.1828067, ..., 1.2374389, 2.1879537,\n",
       "       1.3156186], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_snr_net_ANN(XL1, XH1, XV1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 478us/step\n",
      "[[4.62136269 4.74315895]\n",
      " [4.31896448 4.41793194]\n",
      " [5.00712204 5.29411108]\n",
      " ...\n",
      " [5.46714211 5.69066226]\n",
      " [4.16106319 3.79827401]\n",
      " [4.21725225 4.43522929]]\n"
     ]
    }
   ],
   "source": [
    "# left: predicted snr, right: actual snr\n",
    "y_pred = predict_snr_net_ANN(XL1, XH1, XV1).flatten()\n",
    "idx = (y_pred>4) & (y_pred<10)\n",
    "y_pred_ = y_pred[idx]\n",
    "y_true_ = yNET[idx]\n",
    "print(np.concatenate((y_pred_.reshape(len(y_pred_),1), y_true_.reshape(len(y_true_),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step\n",
      "[[49723    28]\n",
      " [   24   225]]\n",
      "Accuracy: 99.896%\n"
     ]
    }
   ],
   "source": [
    "y_pred_ = predict_snr_net_ANN(XL1, XH1, XV1).flatten()\n",
    "y_test_ = yNET\n",
    "cm = confusion_matrix((y_test_>8), ((y_pred_)>8))\n",
    "print(cm)\n",
    "accuracy = accuracy_score((y_test_>8), (y_pred_>8))*100\n",
    "print(f\"Accuracy: {accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope: -0.0027, intercept: 0.1292\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to create error ajustment\n",
    "\n",
    "# do linear fitting of the error y_pred-y_test\n",
    "def func(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "idx = (y_pred_>4) & (y_pred_<10)\n",
    "idx = idx & (y_test_!=0)\n",
    "popt, pcov = curve_fit(func, y_pred_[idx], y_pred_[idx]-y_test_[idx])\n",
    "print(f\"slope: {popt[0]:.4f}, intercept: {popt[1]:.4f}\")\n",
    "\n",
    "try:\n",
    "    adjustment_dict = load_json('error_adjustment_final.json')\n",
    "except:\n",
    "    adjustment_dict = {}\n",
    "adjustment_dict['L1H1V1'] = {'slope': popt[0], 'intercept': popt[1]}\n",
    "# save json\n",
    "save_json('error_adjustment_final.json', adjustment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "[[49735    16]\n",
      " [   30   219]]\n",
      "Accuracy (after error ajustment): 99.908%\n"
     ]
    }
   ],
   "source": [
    "# load json\n",
    "adjustment_dict = load_json('error_adjustment_final.json')\n",
    "a = adjustment_dict['L1H1V1']['slope']\n",
    "b = adjustment_dict['L1H1V1']['intercept']\n",
    "\n",
    "y_pred_ = predict_snr_net_ANN(XL1, XH1, XV1).flatten()\n",
    "y_pred_ = y_pred_-(a*y_pred_ + b)\n",
    "y_test_ = yNET\n",
    "cm = confusion_matrix((y_test_>8), ((y_pred_)>8))\n",
    "print(cm)\n",
    "accuracy = accuracy_score((y_test_>8), (y_pred_>8))*100\n",
    "print(f\"Accuracy (after error ajustment): {accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = (y_pred_>4) & (y_pred_<12)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(y_pred_[idx], y_pred_[idx]-y_test_[idx], alpha=0.1)\n",
    "plt.xlabel(\"Predicted SNR\")\n",
    "#plt.xscale(\"log\")\n",
    "plt.xlim(4,10)\n",
    "plt.ylabel(\"Error\")\n",
    "plt.ylim(-5,5)\n",
    "plt.grid(alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The error is confined to $\\text{SNR}_{-3}^{+3}$, near SNR=8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 3, 'b': 2, 'c': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1= {'a': 1, 'b': 2}\n",
    "dict2 = {'a': 3, 'c': 4}\n",
    "dict1.update(dict2)\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('c' in dict1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_path_dict = dict()\n",
    "ann_path_dict['L1'] = dict(\n",
    "    model_path='ann_model_L1_O4.h5', \n",
    "    scaler_path='scaler_L1_O4.pkl', \n",
    "    error_adjustment_path='error_adjustment_L1_O4.json',\n",
    "    sampling_frequency=2048.0, \n",
    "    minimum_frequency=20.0, \n",
    "    waveform_approximant='IMRPhenomXPHM', \n",
    "    snr_th=8.0\n",
    "    )\n",
    "ann_path_dict['H1'] = dict(\n",
    "    model_path='ann_model_H1_O4.h5', \n",
    "    scaler_path='scaler_H1_O4.pkl', \n",
    "    error_adjustment_path='error_adjustment_H1_O4.json',\n",
    "    sampling_frequency=2048.0, \n",
    "    minimum_frequency=20.0, \n",
    "    waveform_approximant='IMRPhenomXPHM', \n",
    "    snr_th=8.0\n",
    "    )\n",
    "ann_path_dict['V1'] = dict(\n",
    "    model_path='ann_model_V1_O4.h5', \n",
    "    scaler_path='scaler_V1_O4.pkl', \n",
    "    error_adjustment_path='error_adjustment_V1_O4.json',\n",
    "    sampling_frequency=2048.0, \n",
    "    minimum_frequency=20.0, \n",
    "    waveform_approximant='IMRPhenomXPHM', \n",
    "    snr_th=8.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# save json\n",
    "with open('../gwsnr/ann/ann_path_dict.json', 'w') as f:\n",
    "    json.dump(ann_path_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ann_modelL1_final.h5 ../gwsnr/ann/ann_model_L1_O4.h5\n",
    "! cp scalerL1_final.pkl ../gwsnr/ann/scaler_L1_O4.pkl\n",
    "! cp ann_modelH1_final.h5 ../gwsnr/ann/ann_model_H1_O4.h5\n",
    "! cp scalerH1_final.pkl ../gwsnr/ann/scaler_H1_O4.pkl\n",
    "! cp ann_modelV1_final.h5 ../gwsnr/ann/ann_model_V1_O4.h5\n",
    "! cp scalerV1_final.pkl ../gwsnr/ann/scaler_V1_O4.pkl\n",
    "! cp error_adjustmentL1_final.json ../gwsnr/ann/error_adjustment_L1_O4.json\n",
    "! cp error_adjustmentH1_final.json ../gwsnr/ann/error_adjustment_H1_O4.json\n",
    "! cp error_adjustmentV1_final.json ../gwsnr/ann/error_adjustment_V1_O4.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
