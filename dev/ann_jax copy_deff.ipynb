{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "from ler.utils import append_json, load_json\n",
    "import numpy as np\n",
    "unlensed_params = load_json(\"jointL1.json\")\n",
    "snr = np.array(unlensed_params['L1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psds not given. Choosing bilby's default psds\n",
      "Interpolator will be loaded for L1 detector from ./interpolator_pickle/L1/halfSNR_dict_0.pickle\n",
      "Interpolator will be loaded for H1 detector from ./interpolator_pickle/H1/halfSNR_dict_0.pickle\n",
      "Interpolator will be loaded for V1 detector from ./interpolator_pickle/V1/halfSNR_dict_0.pickle\n"
     ]
    }
   ],
   "source": [
    "# let's generate IMRPhenomD (spinless) interpolartor\n",
    "from gwsnr import GWSNR\n",
    "gwsnr = GWSNR(gwsnr_verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get half_snr \n",
    "# open pickle file\n",
    "import pickle\n",
    "with open('./interpolator_pickle/L1/halfSNR_dict_0.pickle', 'rb') as f:\n",
    "    half_snr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwsnr import antenna_response_array, cubic_spline_interpolator2d\n",
    "\n",
    "def input_output(idx, params):\n",
    "\n",
    "    det_idx = 0 # L1\n",
    "\n",
    "    mass_1 = np.array(params['mass_1'])[idx]\n",
    "    mass_2 = np.array(params['mass_2'])[idx]\n",
    "    luminosity_distance = np.array(params['luminosity_distance'])[idx]\n",
    "    theta_jn = np.array(params['theta_jn'])[idx]\n",
    "    psi = np.array(params['psi'])[idx]\n",
    "    geocent_time = np.array(params['geocent_time'])[idx]\n",
    "    ra = np.array(params['ra'])[idx]\n",
    "    dec = np.array(params['dec'])[idx]\n",
    "    \n",
    "    detector_tensor = gwsnr.detector_tensor_list\n",
    "    snr_halfscaled = np.array(gwsnr.snr_halfsacaled_list)\n",
    "    ratio_arr = gwsnr.ratio_arr\n",
    "    mtot_arr = gwsnr.mtot_arr\n",
    "    \n",
    "    size = len(mass_1)\n",
    "    len_ = len(detector_tensor)\n",
    "    mtot = mass_1 + mass_2\n",
    "    ratio = mass_2 / mass_1\n",
    "    # get array of antenna response\n",
    "    Fp, Fc = antenna_response_array(ra, dec, geocent_time, psi, detector_tensor)\n",
    "\n",
    "    Mc = ((mass_1 * mass_2) ** (3 / 5)) / ((mass_1 + mass_2) ** (1 / 5))\n",
    "    eta = mass_1 * mass_2/(mass_1 + mass_2)**2.\n",
    "    A1 = Mc ** (5.0 / 6.0)\n",
    "    ci_2 = np.cos(theta_jn) ** 2\n",
    "    ci_param = ((1 + np.cos(theta_jn) ** 2) / 2) ** 2\n",
    "    \n",
    "    size = len(mass_1)\n",
    "    snr_half_ = np.zeros((len_,size))\n",
    "    d_eff = np.zeros((len_,size))\n",
    "\n",
    "    # loop over the detectors\n",
    "    for j in range(len_):\n",
    "        # loop over the parameter points\n",
    "        for i in range(size):\n",
    "            snr_half_coeff = snr_halfscaled[j]\n",
    "            snr_half_[j,i] = cubic_spline_interpolator2d(mtot[i], ratio[i], snr_half_coeff, mtot_arr, ratio_arr)\n",
    "            d_eff[j,i] =luminosity_distance[i] / np.sqrt(\n",
    "                    Fp[j,i]**2 * ci_param[i] + Fc[j,i]**2 * ci_2[i]\n",
    "                )\n",
    "\n",
    "    #amp0\n",
    "    amp0 =  A1 / d_eff\n",
    "\n",
    "    # get spin parameters\n",
    "    a_1 = np.array(params['a_1'])[idx]\n",
    "    a_2 = np.array(params['a_2'])[idx]\n",
    "    tilt_1 = np.array(params['tilt_1'])[idx]\n",
    "    tilt_2 = np.array(params['tilt_2'])[idx]\n",
    "    phi_12 = np.array(params['phi_12'])[idx]\n",
    "    phi_jl = np.array(params['phi_jl'])[idx]\n",
    "\n",
    "    # input data\n",
    "    # X = np.vstack([L1, amp0, Mc, eta, theta_jn, a_1, a_2, tilt_1, tilt_2, phi_12, phi_jl]).T\n",
    "    # X = np.vstack([snr_half_[det_idx], amp0[det_idx], eta, a_1, a_2, tilt_1, tilt_2, phi_12, phi_jl]).T\n",
    "    X = np.vstack([snr_half_[det_idx], Mc, eta, a_1, a_2, tilt_1, tilt_2, phi_12, phi_jl]).T\n",
    "\n",
    "    # output data\n",
    "    # get L1 snr for y train \n",
    "    # y = snr[idx]\n",
    "    y = snr[idx]/d_eff[det_idx]\n",
    "\n",
    "    return(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['zs', 'geocent_time', 'ra', 'dec', 'phase', 'psi', 'theta_jn', 'a_1', 'a_2', 'tilt_1', 'tilt_2', 'phi_12', 'phi_jl', 'luminosity_distance', 'mass_1_source', 'mass_2_source', 'mass_1', 'mass_2', 'L1', 'H1', 'V1', 'optimal_snr_net'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set\n",
    "unlensed_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114180"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_min = 6.\n",
    "snr_max = 10.\n",
    "bool_ = (snr>snr_min) & (snr<snr_max) \n",
    "\n",
    "len_ = len(snr)\n",
    "idx = np.arange(len_)\n",
    "# randomize the train set\n",
    "idx = np.random.choice(idx, len(idx), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = input_output(idx, unlensed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114180, 9)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now back to ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91344, 9)\n",
      "(22836, 9)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00476657, -0.96844986, -1.02585849,  0.16104571, -1.40068119,\n",
       "       -0.61825337,  1.00162672, -1.5682502 ,  0.41691657])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ANN\n",
    "ann = tf.keras.models.Sequential() \n",
    "\n",
    "# adding the input layer and the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=9, activation='relu'))\n",
    "# adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "# adding the third hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='sigmoid'))\n",
    "# adding the output layer, absolute value of the snr\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "#ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the ANN\n",
    "# loss = 'mean_squared_error'\n",
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2855/2855 [==============================] - 2s 490us/step - loss: 0.1091 - accuracy: 0.0326\n",
      "Epoch 2/100\n",
      "2855/2855 [==============================] - 1s 496us/step - loss: 0.1083 - accuracy: 0.0326\n",
      "Epoch 3/100\n",
      "2855/2855 [==============================] - 1s 479us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 4/100\n",
      "2855/2855 [==============================] - 1s 491us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 5/100\n",
      "2855/2855 [==============================] - 1s 478us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 6/100\n",
      "2855/2855 [==============================] - 1s 502us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 7/100\n",
      "2855/2855 [==============================] - 1s 488us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 8/100\n",
      "2855/2855 [==============================] - 1s 493us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 9/100\n",
      "2855/2855 [==============================] - 1s 482us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 10/100\n",
      "2855/2855 [==============================] - 1s 483us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 11/100\n",
      "2855/2855 [==============================] - 1s 492us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 12/100\n",
      "2855/2855 [==============================] - 1s 484us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 13/100\n",
      "2855/2855 [==============================] - 1s 499us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 14/100\n",
      "2855/2855 [==============================] - 1s 484us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 15/100\n",
      "2855/2855 [==============================] - 1s 502us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 16/100\n",
      "2855/2855 [==============================] - 1s 482us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 17/100\n",
      "2855/2855 [==============================] - 1s 494us/step - loss: 0.1084 - accuracy: 0.0326\n",
      "Epoch 18/100\n",
      "2855/2855 [==============================] - 1s 495us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 19/100\n",
      "2855/2855 [==============================] - 1s 500us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 20/100\n",
      "2855/2855 [==============================] - 1s 483us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 21/100\n",
      "2855/2855 [==============================] - 1s 498us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 22/100\n",
      "2855/2855 [==============================] - 1s 493us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 23/100\n",
      "2855/2855 [==============================] - 1s 507us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 24/100\n",
      "2855/2855 [==============================] - 1s 491us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 25/100\n",
      "2855/2855 [==============================] - 1s 497us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 26/100\n",
      "2855/2855 [==============================] - 1s 496us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 27/100\n",
      "2855/2855 [==============================] - 1s 487us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 28/100\n",
      "2855/2855 [==============================] - 1s 496us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 29/100\n",
      "2855/2855 [==============================] - 1s 490us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 30/100\n",
      "2855/2855 [==============================] - 1s 495us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 31/100\n",
      "2855/2855 [==============================] - 1s 490us/step - loss: 0.1083 - accuracy: 0.0326\n",
      "Epoch 32/100\n",
      "2855/2855 [==============================] - 1s 496us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 33/100\n",
      "2855/2855 [==============================] - 1s 494us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 34/100\n",
      "2855/2855 [==============================] - 1s 503us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 35/100\n",
      "2855/2855 [==============================] - 1s 484us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 36/100\n",
      "2855/2855 [==============================] - 1s 501us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 37/100\n",
      "2855/2855 [==============================] - 1s 497us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 38/100\n",
      "2855/2855 [==============================] - 1s 487us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 39/100\n",
      "2855/2855 [==============================] - 1s 511us/step - loss: 0.1083 - accuracy: 0.0326\n",
      "Epoch 40/100\n",
      "2855/2855 [==============================] - 2s 729us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 41/100\n",
      "2855/2855 [==============================] - 2s 732us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 42/100\n",
      "2855/2855 [==============================] - 2s 792us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 43/100\n",
      "2855/2855 [==============================] - 2s 709us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 44/100\n",
      "2855/2855 [==============================] - 1s 507us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 45/100\n",
      "2855/2855 [==============================] - 1s 520us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 46/100\n",
      "2855/2855 [==============================] - 1s 518us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 47/100\n",
      "2855/2855 [==============================] - 1s 518us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 48/100\n",
      "2855/2855 [==============================] - 1s 522us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 49/100\n",
      "2855/2855 [==============================] - 2s 563us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 50/100\n",
      "2855/2855 [==============================] - 1s 515us/step - loss: 0.1082 - accuracy: 0.0326\n",
      "Epoch 51/100\n",
      "2855/2855 [==============================] - 1s 519us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 52/100\n",
      "2855/2855 [==============================] - 1s 503us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 53/100\n",
      "2855/2855 [==============================] - 1s 518us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 54/100\n",
      "2855/2855 [==============================] - 1s 505us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 55/100\n",
      "2855/2855 [==============================] - 1s 517us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 56/100\n",
      "2855/2855 [==============================] - 1s 507us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 57/100\n",
      "2855/2855 [==============================] - 1s 497us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 58/100\n",
      "2855/2855 [==============================] - 1s 513us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 59/100\n",
      "2855/2855 [==============================] - 1s 515us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 60/100\n",
      "2855/2855 [==============================] - 1s 513us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 61/100\n",
      "2855/2855 [==============================] - 1s 503us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 62/100\n",
      "2855/2855 [==============================] - 1s 510us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 63/100\n",
      "2855/2855 [==============================] - 1s 501us/step - loss: 0.1081 - accuracy: 0.0326\n",
      "Epoch 64/100\n",
      "2855/2855 [==============================] - 1s 514us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 65/100\n",
      "2855/2855 [==============================] - 1s 498us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 66/100\n",
      "2855/2855 [==============================] - 1s 514us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 67/100\n",
      "2855/2855 [==============================] - 1s 502us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 68/100\n",
      "2855/2855 [==============================] - 1s 510us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 69/100\n",
      "2855/2855 [==============================] - 1s 498us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 70/100\n",
      "2855/2855 [==============================] - 1s 508us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 71/100\n",
      "2855/2855 [==============================] - 1s 507us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 72/100\n",
      "2855/2855 [==============================] - 1s 500us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 73/100\n",
      "2855/2855 [==============================] - 1s 504us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 74/100\n",
      "2855/2855 [==============================] - 1s 512us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 75/100\n",
      "2855/2855 [==============================] - 1s 514us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 76/100\n",
      "2855/2855 [==============================] - 1s 517us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 77/100\n",
      "2855/2855 [==============================] - 1s 511us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 78/100\n",
      "2855/2855 [==============================] - 1s 500us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 79/100\n",
      "2855/2855 [==============================] - 1s 512us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 80/100\n",
      "2855/2855 [==============================] - 1s 502us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 81/100\n",
      "2855/2855 [==============================] - 1s 510us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 82/100\n",
      "2855/2855 [==============================] - 1s 504us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 83/100\n",
      "2855/2855 [==============================] - 2s 527us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 84/100\n",
      "2855/2855 [==============================] - 1s 504us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 85/100\n",
      "2855/2855 [==============================] - 1s 519us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 86/100\n",
      "2855/2855 [==============================] - 1s 499us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 87/100\n",
      "2855/2855 [==============================] - 1s 514us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 88/100\n",
      "2855/2855 [==============================] - 1s 502us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 89/100\n",
      "2855/2855 [==============================] - 1s 509us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 90/100\n",
      "2855/2855 [==============================] - 1s 497us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 91/100\n",
      "2855/2855 [==============================] - 1s 508us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 92/100\n",
      "2855/2855 [==============================] - 1s 502us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 93/100\n",
      "2855/2855 [==============================] - 1s 513us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 94/100\n",
      "2855/2855 [==============================] - 1s 500us/step - loss: 0.1080 - accuracy: 0.0326\n",
      "Epoch 95/100\n",
      "2855/2855 [==============================] - 1s 511us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 96/100\n",
      "2855/2855 [==============================] - 1s 495us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 97/100\n",
      "2855/2855 [==============================] - 1s 508us/step - loss: 0.1078 - accuracy: 0.0326\n",
      "Epoch 98/100\n",
      "2855/2855 [==============================] - 1s 497us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 99/100\n",
      "2855/2855 [==============================] - 1s 509us/step - loss: 0.1079 - accuracy: 0.0326\n",
      "Epoch 100/100\n",
      "2855/2855 [==============================] - 1s 514us/step - loss: 0.1078 - accuracy: 0.0326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ec65f820>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the ANN on the training set\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100, workers=4, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714/714 [==============================] - 0s 276us/step\n",
      "[[2.13041157e-03 6.08911057e-04]\n",
      " [2.13041157e-03 0.00000000e+00]\n",
      " [2.13041157e-03 3.44329614e-03]\n",
      " [2.13041157e-03 7.96389030e-03]\n",
      " [2.13041157e-03 1.80354025e-05]\n",
      " [2.13041157e-03 1.71608966e-05]\n",
      " [2.13041157e-03 5.86634198e-04]\n",
      " [2.13041157e-03 1.70099235e-03]\n",
      " [2.13041157e-03 7.35290216e-07]\n",
      " [2.13041157e-03 1.34339641e-05]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "#y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (y_test>4) & (y_test<100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    x0_image_position,\n",
    "    x1_image_position,\n",
    ") = lens_eq_solver.image_position_from_source(\n",
    "    sourcePos_x=x_source,\n",
    "    sourcePos_y=y_source,\n",
    "    kwargs_lens=kwargs_lens,\n",
    "    solver=\"analytical\",\n",
    "    magnification_limit=1.0 / 1000.0,\n",
    "    arrival_time_sort=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22836\n",
      "13038\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hist_ = y_pred.flatten()-y_test\n",
    "print(len(hist_))\n",
    "hist_ = hist_[idx]\n",
    "#hist_ = hist_[abs(hist_)<5.]\n",
    "print(len(hist_))\n",
    "plt.figure(figsize=(4,4)) \n",
    "plt.hist(hist_, bins=100, histtype='step', density=True)\n",
    "plt.xlim(-3,3)\n",
    "plt.xlabel('snr_ml and snr_inner_product difference')\n",
    "plt.ylabel('pdf')\n",
    "plt.grid(alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, accuracy_score\n\u001b[0;32m----> 2\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm)\n\u001b[1;32m      4\u001b[0m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/ler/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ler/lib/python3.10/site-packages/sklearn/metrics/_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/ler/lib/python3.10/site-packages/sklearn/metrics/_classification.py:104\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    107\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ler",
   "language": "python",
   "name": "ler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
